\documentclass[a4paper,fontsize=10pt,twoside,DIV15,BCOR12mm,headinclude=true,footinclude=false,pagesize,bibtotoc]{scrbook}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{pslatex} % -- times instead of computer modern
\usepackage[scaled=.84]{beramono} % a sane monospace font
\usepackage{microtype}

\usepackage{url}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xspace}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{colortbl}
\usepackage{multicol}
\usepackage{rotating}
\usepackage{subfig}
\usepackage{ulem}
\usepackage{enumerate}
\usepackage{framed}

% avoid clubs and widows
\clubpenalty=10000
\widowpenalty=10000

% tweak float placement
%% \renewcommand{\textfraction}{.15}
\renewcommand{\topfraction}{.75}
%% \renewcommand{\bottomfraction}{.7}
\renewcommand{\floatpagefraction}{.75}
%% \renewcommand{\dbltopfraction}{.66}
%% \renewcommand{\dblfloatpagefraction}{.66}
\setcounter{topnumber}{4}
%% \setcounter{bottomnumber}{4}
%% \setcounter{totalnumber}{16}
%% \setcounter{dbltopnumber}{4}

\newcommand{\code}[1]{{\texttt{#1}}}
\newcommand{\codefoot}[1]{{\textsf{#1}}}
\def\figref#1{Figure~\ref{fig:#1}}

% ulem package, otherwise emphasized text becomes underlined
\normalem


\newcommand{\todo}[1]{{\emph{TODO: #1}}}
%\renewcommand{\todo}[1]{}

%
% generic command to comment something
%
\newcommand{\comment}[3]{

\textsf{\textbf{#1}} {\color{#3}#2}}

%
% commentators
%
\newcommand{\tommy}[1]{\comment{Tommy}{#1}{Red}}
\newcommand{\wolf}[1]{\comment{Wolfgang}{#1}{OliveGreen}}
\newcommand{\martin}[1]{\comment{Martin}{#1}{Blue}}
\newcommand{\stefan}[1]{\comment{Stefan}{#1}{RoyalPurple}}
\newcommand{\daniel}[1]{\comment{Daniel}{#1}{RoyalBlue}}
\newcommand{\cullmann}[1]{\comment{Christoph}{#1}{Maroon}}
\newcommand{\gebhard}[1]{\comment{Gernot}{#1}{RedOrange}}
\newcommand{\fb}[1]{\comment{Florian}{#1}{Emerald}}
\newcommand{\jack}[1]{\comment{Jack}{#1}{Magenta}}
\newcommand{\sahar}[1]{\comment{Sahar}{#1}{Green}}
\newcommand{\rasmus}[1]{\comment{Rasmus}{#1}{Mahogany}}

% uncomment to get rid of comments
\renewcommand{\tommy}[1]{}
\renewcommand{\wolf}[1]{}
\renewcommand{\martin}[1]{}
\renewcommand{\stefan}[1]{}
\renewcommand{\daniel}[1]{}
\renewcommand{\cullmann}[1]{}
\renewcommand{\gebhard}[1]{}
\renewcommand{\fb}[1]{}
\renewcommand{\jack}[1]{}
\renewcommand{\sahar}[1]{}
\renewcommand{\rasmus}[1]{}

%
% custom colors
%
\definecolor{lightgray}{gray}{0.8}
\definecolor{gray}{gray}{0.5}

\usepackage{listings}

% general style for listings
\lstset{basicstyle=\ttfamily,keywordstyle=\ttfamily,showstringspaces=false,language=C}

\usepackage[endianness=big]{bytefield}

% long immediate in second slot
\newcommand{\lconst}{\texttt{const}_{32}}
% short immediate in ALU instruction
\newcommand{\sconst}{\texttt{Constant}_{12}}
% constant in Rs2 field
\newcommand{\rconst}{\texttt{Constant}_{5}}

% SH: to be used in text mode .. maybe we should change this to math mode?
\newcommand{\XOR}{\textasciicircum\xspace}
\newcommand{\OR}{\textbar\xspace}
\newcommand{\AND}{\&\xspace}
\newcommand{\NOT}{\texttildelow}
\newcommand{\shl}{\textless$\!$\textless\xspace}
\newcommand{\shr}{\textgreater$\!$\textgreater$\!$\textgreater\xspace}
\newcommand{\ashr}{\textgreater$\!$\textgreater\xspace}

\newcommand{\bitsunused}{\rule{\width}{\height}}
\newcommand{\bitssubclass}{\color{lightgray}\rule{\width}{\height}}

%
% allow click-able links
%
\usepackage[open]{bookmark}
\usepackage[all]{hypcap}

%
% hyperref setup (depends on bookmark/hyperref}
%
\hypersetup{
    pdftitle = {Patmos Reference Handbook},
    pdfsubject = {Technical Report},
    colorlinks = {true},
    citecolor = {black},
    filecolor = {black},
    linkcolor = {black},
    urlcolor = {black},
    final
}

%
% document contents
%
\begin{document}

\title{Patmos Reference Handbook}

\author{Martin Schoeberl, Florian Brandner, Stefan Hepp,\\Wolfgang Puffitsch, Daniel Prokesch}

\lowertitleback{Copyright \copyright{} 2014 Technical University of Denmark
  \medskip\\
  \begin{tabular}{lp{.8\textwidth}}
    \raisebox{-12pt}{\includegraphics[height=18pt]{fig/cc_by_sa}} &
     This work is licensed under a Creative Commons Attribution-ShareAlike
     4.0 International License.
     \url{http://creativecommons.org/licenses/by-sa/4.0/}\\
  \end{tabular}
}

\frontmatter

\maketitle

\chapter{Preface}

This handbook shall evolve to the documentation of the Patmos processor and the
Patmos compiler. In the mean time it is intended to collect design notes and discussions.
Especially ISA design notes now.

The latest version of this handbook is contained as LaTeX source in the Patmos repository in directory
\code{patmos/doc/handbook} and can be built with \code{make}.

\section*{Acknowledgment}

We would like to thank Tommy Thorn for the always intense and enjoyable
discussions of the Patmos ISA and processor design in general.
Jack Whitham offered his experience with RISC
ISA design and trade-offs.
Gernot Gebhard and Christoph Cullmann gave valuable feedback on the ISA
related to WCET analysis.
Sahar Abbaspourseyedi is working on the stack
cache and verifies the ideas and concepts presented here. We thank
Rasmus Bo S{\o}rensen for fixing some documentation errors.

This work was partially funded under the
European Union's 7th Framework Programme
under grant agreement no. 288008:
Time-predictable Multi-Core Architecture for Embedded
Systems (T-CREST).

\tableofcontents

\begingroup
\let\cleardoublepage\clearpage
\listoffigures
\listoftables
\lstlistoflistings
\endgroup

\mainmatter

\chapter{Introduction}

Real-time systems need a time-predictable execution platform so that the worst-case execution time (WCET) can be statically estimated. It has been argued that we have to rethink computer architecture for real-time systems instead of trying to catch up with new processors in the WCET analysis tools~\cite{tpca:jes, pret:dac2007}.

We present the time-predictable processor Patmos as one approach to attack the complexity issue of WCET analysis. Patmos is a static scheduled, dual-issue RISC processor that is optimized for real-time systems.

\martin{This report shall converge towards a real manual. At the moment it serves
discussion well, but we shall keep this in mind. Here a starting list of TODOs:

\begin{itemize}
\item Send an email to all and ask about cleanup of some discussion points
\item Convert some discussion text into readable sections and argue why we
did what we did
\item Get a nice introduction and a good architecture section written
\end{itemize}

}

%\chapter{Related Work}
%\label{sec:related}


\fb{Martin wishes that Patmos will not require more than 3000 LC ;-)}
\martin{And fmax shall not be below 80\% of NIOS or MicroBlaze.
And performance (also average case ;-) shall be better, compared to NIOS/MB.
And we could compare against Tommy's YARI.}

\martin{TODO: The instruction description with the individual pipeline stages shall be
rewritten to reflect the actual simulator and hardware implementation of Patmos.
E.g. predicate registers are *not* read in the decode stage, but directly in EX.
Reading in decode would mean a one cycle generate use delay.}


\chapter{The Architecture of Patmos}
\label{sec:arch}

\section{Pipeline}

Figure~\ref{fig:pipeline} shows an overview of Patmos' pipeline. The pipeline
consist of 5 stages: (1) instruction fetch (\texttt{FE}), (2) decode and
register read (\texttt{DEC}), (3) execute (\texttt{EX}), (4) memory access (\texttt{MEM}), and (5) register write  back (\texttt{WB}).

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{fig/pipeline}
    \caption{Pipeline of Patmos with fetch, decode, execute, memory, and write back stages.}\label{fig:pipeline}
\end{figure}

Some instructions define additional pipeline stages. Multiplication instructions
are executed, starting from the \texttt{EX} stage, in a parallel pipeline with
fixed-length (see the instruction definition). The respective stages are
referred to by \texttt{EX$_1$}, \dots, \texttt{EX$_n$}.

\martin{\todo{A more detailed description of the pipeline stages, as the individual
4 stage description is gone.} Here a start:}

\subsection{Fetch}

Fetch one or two words of instruction from the ROM or method cache.
Calculate next PC depending on the length of the instruction bundle.

\subsection{Decode}

Decode the instruction and generate control signals for the following stages.
Read register operands. Sign or zero extend immediate operands.

\subsection{Execute}

Read predicate registers. Conditional execute (ALU) instructions.
Write predicate register. Calculate effective address for memory operations.

\subsection{Memory}

Read or write memory. This is the only pipeline stage that might
stall the pipeline.

\subsection{Write Back}

Write result into destination register.

\stefan{Note that in the \texttt{pasim} simulator the Memory and Write Back stages are merged into a single MW stage at the time of writing,
and the stages are simulated from back to front.
While this has no effect on the timing and hazards of the instructions, there is only a single bypass from MW to EX (per pipeline). Apart
from that, all implementations of all instructions in the simulator should adhere to the above description of the stages.}

\section{Local Memories}

Patmos contains several on-chip memories, as sketched in Figure~\ref{fig:pipeline}.
We apply the idea of split caches~\cite{jop:dcache:rts} to simplify and enhance
the cache analysis. Instructions are fetched from the method cache that caches
whole methods. Patmos also supports instruction and data scratchpad memories.
Stack allocated data is cached in a stack cache and we envision also a normal
data cache with LRU replacement. Accesses to data that are hard to analyze can
bypass the data cache.

% \cite{jop:ocwcet:ccpe}



\section{Register Files}

The register files available in Patmos are depicted by
Figure~\ref{fig:registers}. In short, Patmos offers:
\begin{itemize}
  \item 32, 32-bit general-purpose registers (\texttt{R}) : \texttt{r0}, \dots, \texttt{r31} \\
    \texttt{r0} is read-only, set to zero (\texttt{0}).
  \item 8, single-bit predicate registers (\texttt{P}): \texttt{p0}, \dots, \texttt{p7}, \\
    \texttt{p0} is read-only, set to \texttt{true} (\texttt{1}).
  \item 16, 32-bit special-purpose registers (\texttt{S}): \texttt{s0}, \dots, \texttt{s15}
\end{itemize}

The general-purpose registers \texttt{R} are read in the \code{DEC} stage
and written in the \code{WB} stage. Full forwarding makes them available
in the \code{EX} stage before written into the register file.

The predicate registers are single bits that are set and read in the \code{EX}
stage.

The special registers \code{S} is just a collection of various `special'
processor registers. These registers might be used by different units/stages
in the pipeline and are not physically collected in a `register file'.
The pipeline stage where those registers are read and written by the
\code{mfs} and \code{mts} are dependent on the type of the special
register.

\martin{The three `register' files shall constitute the state of the processor.
Every non-obvious register, such as method base, shall be mapped to a
`special' register. Even the current PC on an interrupt shall end up in a
register that is mapped into the special register domain.}

\stefan{Umm .. it would be really good to define somewhere in which stages which special register is actually read or written by mfs/mts
;).}

So all-in-all the recoverable process state is: general-purpose registers
\code{R}, the predicates \code{P}, and a collection of various processor
registers mapped to the `special' register files \code{S}.

Concurrently writing and reading the same register in the same cycle
will, for the read, yield the old value of the register. Reads in
subsequent cycles return the result most recently written to the
register, i.e., the pipeline implements full forwarding.

When writing concurrently to the same register, the result is
undefined. If two instructions of the current bundle have the same
destination register, the result is only defined if the predicate of
at most one instruction in the bundle evaluates to \texttt{true} (1).

\wolf{In practice, the result is even defined if both instructions
  write to the same register, but I would not make this a feature of
  the ISA.}

The predicate registers are usually encoded as $4$-bit operands, where the most
significant bit indicates that the value read from the register file should be
inverted before it is used. For operands that are written, this additional bit
is omitted.

The special-purpose registers of \texttt{S} allow access to some dedicated
registers:
\begin{itemize}
  \item The lower $8$ bits of \texttt{s0} can be used to save/restore
    \emph{all} predicate registers at once. The other bits of that
    register are currently reserved, but not used. Setting the reserved
	bits has no effect.
  \item \texttt{s2} and \texttt{s3} can also be accessed through the names
    \texttt{sl} and \texttt{sh} and represent the lower and upper
    32-bits a multiplication.
  \item \texttt{s5} can also be accessed through the name \texttt{ss} and
    represents the register pointing to the top of the saved stack
	content in the main memory (i.e., the current stack spill pointer).
	Updating \texttt{s5} does not change \texttt{s6} or spill the stack cache.
  \item \texttt{s6} can also be accessed through the name \texttt{st} and
    represents a pointer to the top-most element of the content of the
    stack cache.
	Updating \texttt{s6} does not change \texttt{s5} or spill the stack cache.
\end{itemize}

\stefan{None of the registers should be read-only, as they need to be restored when
we switch contexts.}

\begin{figure}[p]

  \begin{multicols}{2}
    \centering

    \subfloat[\label{fig:registers:r}General-Purpose Registers (\texttt{R})]{
      \begin{bytefield}[bitwidth=.59em]{32}
        \bitheader{0-31} \\
        \bitbox{32}{r0 (zero, read-only)} \\
        \bitbox{32}{r1 (result, scratch)} \\
        \bitbox{32}{r2 (result 64-bit, scratch)} \\
        \bitbox{32}{r3 (argument 1, scratch)} \\
        \bitbox{32}{r4 (argument 2, scratch)} \\
        \bitbox{32}{r5 (argument 3, scratch)} \\
        \bitbox{32}{r6 (argument 4, scratch)} \\
        \bitbox{32}{r7 (argument 5, scratch)} \\
        \bitbox{32}{r8 (argument 6, scratch)} \\ \bitbox{32}{r9 (scratch)} \\
        \bitbox{32}{r10 (scratch)} \\ \bitbox{32}{r11 (scratch)} \\
        \bitbox{32}{r12 (scratch)} \\ \bitbox{32}{r13 (scratch)} \\
        \bitbox{32}{r14 (scratch)} \\ \bitbox{32}{r15 (scratch)} \\
        \bitbox{32}{r16 (scratch)} \\ \bitbox{32}{r17 (scratch)} \\
        \bitbox{32}{r18 (scratch)} \\ \bitbox{32}{r19 (scratch)} \\
        \bitbox{32}{r20 (scratch)} \\ \bitbox{32}{r21 (saved)} \\
        \bitbox{32}{r22 (saved)} \\ \bitbox{32}{r23 (saved)} \\
        \bitbox{32}{r24 (saved)} \\ \bitbox{32}{r25 (saved)} \\
        \bitbox{32}{r26 (saved)} \\ \bitbox{32}{r27 (saved)} \\
        \bitbox{32}{r28 (saved)} \\
        \bitbox{32}{r29 (temp.\ register, saved)} \\
        \bitbox{32}{r30 (frame pointer, saved)} \\
        \bitbox{32}{r31 (stack pointer, saved)} \\
      \end{bytefield}
    }

    \newpage

    \vspace*{\stretch{1}}

    \subfloat[\label{fig:registers:pr}Predicate Registers (\texttt{P})]{
      \newcommand{\bitlabel}[1]{
        \bitbox[]{1}{\raisebox{0pt}[5ex][1pt]{\turnbox{45}{\fontsize{7}{7}\selectfont#1}}}
      }
      \begin{bytefield}[bitwidth=1.5em]{8}
        \bitlabel{p7} \bitlabel{p6} \bitlabel{p5} \bitlabel{p4}
        \bitlabel{p3} \bitlabel{p2} \bitlabel{p1} \bitlabel{p0 -- Read only, always \texttt{1}} \\
        \bitheader{0-7} \\
        \bitbox{1}{} \bitbox{1}{} \bitbox{1}{} \bitbox{1}{}
        \bitbox{1}{} \bitbox{1}{} \bitbox{1}{} \bitbox{1}{} \\
      \end{bytefield}
    }

    \vspace*{\stretch{2}}

    \subfloat[\label{fig:registers:s}Special-Purpose Registers (\texttt{S})]{
      \begin{bytefield}[bitwidth=.59em]{32}
        \bitheader{0-31} \\
        \bitbox{24}{reserved} \bitbox{8}{p7 \dots p0} \bitbox[]{4}{s0} \\
        \bitbox{32}{s1} \\
        \bitbox{32}{sl (mul low)} \bitbox[]{4}{s2} \\
        \bitbox{32}{sh (mul high)} \bitbox[]{4}{s3} \\
        \bitbox{32}{s4} \\
        \bitbox{32}{ss (spill pointer)} \bitbox[]{4}{s5} \\
        \bitbox{32}{st (stack pointer)} \bitbox[]{4}{s6} \\
        \bitbox{32}{srb (return base)} \bitbox[]{4}{s7} \\
        \bitbox{32}{sro (return offset)} \bitbox[]{4}{s8} \\
        \bitbox{32}{sxb (exception return base)} \bitbox[]{4}{s9} \\
        \bitbox{32}{sxo (exception return offset)} \bitbox[]{4}{s10} \\
        \bitbox{32}{s11} \\
        \bitbox{32}{s12} \\ \bitbox{32}{s13} \\ \bitbox{32}{s14} \\ \bitbox{32}{s15} \\
      \end{bytefield}
    }

    \vspace*{\stretch{4}}~

  \end{multicols}

  \caption{General-purpose register file, predicate registers, and
           special-purpose registers of Patmos.}
  \label{fig:registers}
\end{figure}

\section{Bundle Formats}

All Patmos instructions are 32 bits wide and are structured according to
one of the instruction formats defined in the following section. Up to two
instructions can be combined to form an instruction bundle; Patmos bundles are
thus either 32 or 64 bits wide. The bundles sizes are recognized by the value of
the most significant bit, where $0$ indicates a short, 32-bit bundle and $1$ a
long, 64-bit bundle.

The following figures illustrate these two bundle variants:
\begin{itemize}
 \item 32-bit bundle format\\[2ex]
   \begin{bytefield}{32}
     \bitheader{0-31} \\
     \bitbox{1}{0} & \bitbox{31}{\bitssubclass} \\
   \end{bytefield}

 \item 64-bit bundle format \\[2ex]
   \begin{bytefield}[lsb=32]{32} \bitheader{32-63} \\
     \bitbox{1}{1} & \bitbox{31}{\bitssubclass} \\
   \end{bytefield}
   \hspace{.5em}
   \begin{bytefield}{32} \bitheader{0-31} \\
     \bitbox{1}{x} & \bitbox{31}{\bitssubclass} \\
   \end{bytefield}
\end{itemize}

\section{Instruction Formats}

This section gives an overview of all instruction formats defined in the Patmos
ISA. Individual instructions of the various formats are defined in the next
section. Gray fields indicate bits whose function is determined by a sub-class
of the instruction format. Black fields are not used.

\begin{itemize}
  \item ALUi -- Arithmetic Immediate \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{2}{00} & \bitbox{3}{Func} &
      \bitbox{5}{Rd} & \bitbox{5}{Rs1} & \bitbox{12}{Immediate} \\
    \end{bytefield}
  \item ALUl -- Long Immediate \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{1} & \bitbox{4}{Pred} & \bitbox{5}{11111} &
      \bitbox{5}{Rd} & \bitbox{5}{Rs1} & \bitbox{5}{\bitsunused} &
      \bitbox{3}{000} & \bitbox{4}{Func} \\
      \bitheader{0-31} \\
      \bitbox{32}{Long Immediate} \\
    \end{bytefield}
  \item ALU -- Arithmetic \\[2ex]
        \begin{bytefield}{32}
          \bitheader{0-31} \\
          \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01000} &
          \bitbox{15}{\bitssubclass} &
          \bitbox{3}{Opc} & \bitbox{4}{Func} \\
        \end{bytefield}

        \begin{bytefield}[leftcurly=.]{32}
          \begin{leftwordgroup}{\parbox{8em}{ALUr -- Register}}
            \bitheader{0-31} \\
            \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01000} &
            \bitbox{5}{Rd} & \bitbox{5}{Rs1} & \bitbox{5}{Rs2} &
            \bitbox{3}{000} & \bitbox{4}{Func}
          \end{leftwordgroup} \\
          \begin{leftwordgroup}{\parbox{8em}{ALUm -- Multiply}}
            \bitheader{0-31} \\
            \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01000} &
            \bitbox{5}{\bitsunused} & \bitbox{5}{Rs1} & \bitbox{5}{Rs2} &
            \bitbox{3}{010} & \bitbox{4}{Func}
          \end{leftwordgroup} \\
          \begin{leftwordgroup}{\parbox{8em}{ALUc -- Compare}}
            \bitheader{0-31} \\
            \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01000} &
            \bitbox{2}{\bitsunused} & \bitbox{3}{Pd} & \bitbox{5}{Rs1} & \bitbox{5}{Rs2} &
            \bitbox{3}{011} & \bitbox{4}{Func}
          \end{leftwordgroup} \\
          \begin{leftwordgroup}{\parbox{8em}{ALUp -- Predicate}}
            \bitheader{0-31} \\
            \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01000} &
            \bitbox{2}{\bitsunused} & \bitbox{3}{Pd} & \bitbox{1}{\bitsunused} & \bitbox{4}{Ps1} & \bitbox{1}{\bitsunused} & \bitbox{4}{Ps2} &
            \bitbox{3}{100} & \bitbox{4}{Func}
          \end{leftwordgroup} \\
          \begin{leftwordgroup}{\parbox{8em}{ALUb -- Bitcopy}}
            \bitheader{0-31} \\
            \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01000} &
            \bitbox{5}{Rd} & \bitbox{5}{Rs1} & \bitbox{5}{Imm} &
            \bitbox{3}{101} & \bitbox{4}{Ps}
          \end{leftwordgroup} \\
          \begin{leftwordgroup}{\parbox{8em}{ALUci -- Compare immediate}}
            \bitheader{0-31} \\
            \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01000} &
            \bitbox{2}{\bitsunused} & \bitbox{3}{Pd} & \bitbox{5}{Rs1} & \bitbox{5}{Imm} &
            \bitbox{3}{110} & \bitbox{4}{Func}
          \end{leftwordgroup} \\
          %% \begin{leftwordgroup}{\parbox{8em}{Unused}}
          %%   \bitheader{0-31} \\
          %%   \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01000} &
          %%   \bitbox{15}{\bitssubclass} &
          %%   \bitbox{3}{111} & \bitbox{4}{Func}
          %% \end{leftwordgroup} \\
        \end{bytefield}

  \item SPC -- Special \\[2ex]
        \begin{bytefield}{32}
          \bitheader{0-31} \\
          \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01001} &
          \bitbox{15}{\bitssubclass} &
          \bitbox{3}{Opc} & \bitbox{4}{I/R/F} \\
        \end{bytefield}

        \begin{bytefield}[leftcurly=.]{32}
          \begin{leftwordgroup}{\parbox{11em}{SPCt -- Move To Special}}
            \bitheader{0-31} \\
            \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01001} &
            \bitbox{5}{\bitsunused} & \bitbox{5}{Rs1} & \bitbox{5}{\bitsunused} &
            \bitbox{3}{010} & \bitbox{4}{Sd}
          \end{leftwordgroup} \\
          \begin{leftwordgroup}{\parbox{11em}{SPCf -- Move From Special}}
            \bitheader{0-31} \\
            \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01001} &
            \bitbox{5}{Rd} & \bitbox{10}{\bitsunused} &
            \bitbox{3}{011} & \bitbox{4}{Ss}
          \end{leftwordgroup} \\
          %% \begin{leftwordgroup}{\parbox{11em}{Unused}}
          %%   \bitheader{0-31} \\
          %%   \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01001} &
          %%   \bitbox{15}{\bitssubclass} &
          %%   \bitbox{3}{000} & \bitbox{4}{I/R/F}
          %% \end{leftwordgroup} \\
          %% \begin{leftwordgroup}{\parbox{11em}{Unused}}
          %%   \bitheader{0-31} \\
          %%   \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01001} &
          %%   \bitbox{15}{\bitssubclass} &
          %%   \bitbox{3}{100} & \bitbox{4}{I/R/F}
          %% \end{leftwordgroup} \\
          %% \begin{leftwordgroup}{\parbox{11em}{Unused}}
          %%   \bitheader{0-31} \\
          %%   \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01001} &
          %%   \bitbox{15}{\bitssubclass} &
          %%   \bitbox{3}{101} & \bitbox{4}{I/R/F}
          %% \end{leftwordgroup} \\
          %% \begin{leftwordgroup}{\parbox{11em}{Unused}}
          %%   \bitheader{0-31} \\
          %%   \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01001} &
          %%   \bitbox{15}{\bitssubclass} &
          %%   \bitbox{3}{110} & \bitbox{4}{I/R/F}
          %% \end{leftwordgroup} \\
          %% \begin{leftwordgroup}{\parbox{11em}{Unused}}
          %%   \bitheader{0-31} \\
          %%   \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01001} &
          %%   \bitbox{15}{\bitssubclass} &
          %%   \bitbox{3}{111} & \bitbox{4}{I/R/F}
          %% \end{leftwordgroup}
        \end{bytefield}

  \item LDT -- Load Typed \\[2ex]
        \begin{bytefield}{32}
          \bitheader{0-31} \\
          \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01010} &
          \bitbox{5}{Rd} & \bitbox{5}{Ra} & \bitbox{5}{Type} & \bitbox{7}{Offset} \\
        \end{bytefield}
  \item STT -- Store Typed \\[2ex]
        \begin{bytefield}{32}
          \bitheader{0-31} \\
          \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01011} &
          \bitbox{5}{Type} & \bitbox{5}{Ra} & \bitbox{5}{Rs} & \bitbox{7}{Offset} \\
        \end{bytefield}

  \item STC -- Stack Control \\[2ex]
        \begin{bytefield}{32}
          \bitheader{0-31} \\
          \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01100} &
          \bitbox{2}{Op} & \bitbox{2}{F} & \bitbox{18}{\bitssubclass} \\
        \end{bytefield}

        \begin{bytefield}[leftcurly=.]{32}
          \begin{leftwordgroup}{\parbox{13em}{STCi -- Stack Control Immediate}}
            \bitheader{0-31} \\
            \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01100} &
            \bitbox{2}{Op} & \bitbox{2}{00} &
            \bitbox{18}{Immediate}
          \end{leftwordgroup} \\
          \begin{leftwordgroup}{\parbox{13em}{STCr -- Stack Control Register}}
            \bitheader{0-31} \\
            \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01100} &
            \bitbox{2}{Op} & \bitbox{2}{01} &
            \bitbox{1}{\bitsunused} & \bitbox{5}{Rs} & \bitbox{12}{\bitsunused}
          \end{leftwordgroup}
        \end{bytefield}

  \item CFLi -- Control Flow with Immediate \nopagebreak\\[2ex]
        \begin{bytefield}{32}
          \bitheader{0-31} \\
          \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{2}{10} & \bitbox{2}{Op} & \bitbox{1}{d} &
          \bitbox{22}{Immediate} \\
        \end{bytefield}

  \item CFLr -- Control Flow with Registers \\[2ex]
        \begin{bytefield}{32}
          \bitheader{0-31} \\
          \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{4}{1100} & \bitbox{1}{d} &
          \bitbox{18}{\bitssubclass} & \bitbox{2}{F} & \bitbox{2}{Op} \\
        \end{bytefield}

        \begin{bytefield}[leftcurly=.]{32}
          \begin{leftwordgroup}{\parbox{18em}{CFLri -- Control Flow with implicit registers}}
          \bitheader{0-31} \\
          \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{4}{1100} & \bitbox{1}{d} &
          \bitbox{18}{\bitsunused} &
          \bitbox{2}{00} & \bitbox{2}{Op}
          \end{leftwordgroup}\\
          \begin{leftwordgroup}{\parbox{18em}{CFLrs -- Control Flow with single register}}
          \bitheader{0-31} \\
          \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{4}{1100} & \bitbox{1}{d} &
          \bitbox{5}{\bitsunused} & \bitbox{5}{Rs} & \bitbox{8}{\bitsunused} &
          \bitbox{2}{01} & \bitbox{2}{Op}
          \end{leftwordgroup}\\
          \begin{leftwordgroup}{\parbox{18em}{CFLrt -- Control Flow with two registers}}
          \bitheader{0-31} \\
          \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{4}{1100} & \bitbox{1}{d} &
          \bitbox{5}{\bitsunused} & \bitbox{5}{Rs1} & \bitbox{5}{Rs2} & \bitbox{3}{\bitsunused} &
          \bitbox{2}{10} & \bitbox{2}{Op}
          \end{leftwordgroup}
        \end{bytefield}
\end{itemize}

\clearpage
\section{Instruction Opcodes}
\label{sec:instruction_opcodes}

This section defines the instruction set architecture, the instruction opcodes,
and the behavior of the respective instructions of Patmos. This section should
be less used for discussions and should slowly converge to a final definition
of the instruction set.

\subsection{Binary Arithmetic}

Applies to the ALUr, ALUi, and ALUl formats.  Operand \texttt{Op2}
denotes either the \texttt{Rs2}, or the \texttt{Immediate} operand, or
the \texttt{Long Immediate}. The immediate operand is zero-extended.  For
shift and rotate operations, only the lower $5$ bits of the operand
are considered. Table~\ref{tab:alufunc} shows the encoding of the
\texttt{func} field; for ALUi instructions, only functions in the
upper half of that table are available.

\begin{itemize}
  \item ALUr -- Register \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01000} &
      \bitbox{5}{Rd} & \bitbox{5}{Rs1} & \bitbox{5}{Rs2} &
      \bitbox{3}{000} & \bitbox{4}{Func} \\
    \end{bytefield}
  \item ALUi -- Arithmetic Immediate \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{2}{00} & \bitbox{3}{Func} &
      \bitbox{5}{Rd} & \bitbox{5}{Rs1} & \bitbox{12}{Immediate} \\
    \end{bytefield}
  \item ALUl -- Long Immediate\\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{1} & \bitbox{4}{Pred} & \bitbox{5}{11111} &
      \bitbox{5}{Rd} & \bitbox{5}{Rs1} & \bitbox{5}{\bitsunused} &
      \bitbox{3}{000} & \bitbox{4}{Func} \\
      \bitheader{0-31} \\
      \bitbox{32}{Long Immediate} \\
   \end{bytefield}
\end{itemize}

\begin{table}[hb]
  \centering
  \begin{tabular}{lll}
    \toprule
    Func & Name   & Semantics \\
    \midrule
    0000 & add    & \texttt{Rd = Rs1 + Op2} \\
    0001 & sub    & \texttt{Rd = Rs1 - Op2} \\
    0010 & xor    & \texttt{Rd = Rs1 \XOR Op2} \\
    0011 & sl     & \texttt{Rd = Rs1 \shl Op2$_{(4:0)}$} \\
    0100 & sr     & \texttt{Rd = Rs1 \shr Op2$_{(4:0)}$} \\
    0101 & sra    & \texttt{Rd = Rs1 \ashr Op2$_{(4:0)}$} \\
    0110 & or     & \texttt{Rd = Rs1 \OR Op2} \\
    0111 & and    & \texttt{Rd = Rs1 \AND Op2} \\
    \cmidrule{1-3}
    1000 & ---	& unused \\
    1001 & ---    & unused \\
    1010 & ---    & unused \\
    1011 & nor    & \texttt{Rd = \NOT (Rs1 \OR Op2)} \\
    1100 & shadd  & \texttt{Rd = (Rs1 \shl 1) + Op2} \\
    1101 & shadd2 & \texttt{Rd = (Rs1 \shl 2) + Op2} \\
    1110 & ---    & unused \\
    1111 & ---    & unused \\
    \bottomrule
  \end{tabular}
  \caption{General ALU functions}
  \label{tab:alufunc}
\end{table}

\paragraph{Pseudo Instructions}
\begin{itemize}
  \item \texttt{mov Rd = Rs}~\dots~\texttt{add Rd = Rs + 0}
  \item \texttt{clr Rd}~\dots~\texttt{add Rd = r0 + 0}
  \item \texttt{neg Rd = -Rs}~\dots~\texttt{sub Rd = 0 - Rs}
  \item \texttt{not Rd = \NOT Rs}~\dots~\texttt{nor Rd = \NOT (Rs \OR R0)}
  \item \texttt{li Rd = Immediate}~\dots~\texttt{add Rd = r0 + Immediate}
  \item \texttt{li Rd = Immediate}~\dots~\texttt{sub Rd = r0 - Immediate}
  \item \texttt{nop}~\dots~\texttt{sub r0 = r0 - 0}
\end{itemize}


\paragraph{Note}
The use of \texttt{sub r0 = r0 - 0} to encode a \texttt{nop}
pseudo-instruction results in a value of \texttt{0x00400000} in the
binary instruction stream. This helps in distinguishing the execution
of compiler-generated \texttt{nops} from executing instructions from
memory that happens to be zero.

\clearpage
\subsection{Multiply}

Applies to the ALUm format only. Multiplications are executed in
parallel with the regular pipeline and finish within a fixed number of
cycles \todo{how many?}. Table~\ref{tab:mulfunc} shows the encoding of
the \texttt{func} field for the ALUm instruction format.

\begin{itemize}
  \item ALUm -- Multiply \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01000} &
      \bitbox{5}{\bitsunused} & \bitbox{5}{Rs1} & \bitbox{5}{Rs2} &
      \bitbox{3}{010} & \bitbox{4}{Func} \\
    \end{bytefield}
\end{itemize}

\begin{table}[hb]
  \centering
  \begin{tabular}{lll}
    \toprule
    Func & Name   & Semantics \\
    \midrule
    0000 & mul    & \texttt{sl = Rs1 * Rs2;}\\
         &        & \texttt{sh = (Rs1 * Rs2) \shr 32} \\
    0001 & mulu   & \texttt{sl = (uint32\_t)Rs1 * (uint32\_t)Rs2;} \\
         &        & \texttt{sh = ((uint32\_t)Rs1 * (uint32\_t)Rs2) \shr 32} \\
    0010 & ---    & unused \\
    \dots& \dots  & \dots \\
    1111 & ---    & unused \\
    \bottomrule
  \end{tabular}
  \caption{Multiplication functions}
  \label{tab:mulfunc}
\end{table}


\paragraph{Behavior}

Perform multiplication in multiple cycles and write the result into
destination registers \texttt{sl} and \texttt{sh}.

\paragraph{Note}

Multiplications are pipelined, it is thus possible to issue one multiplication on
every cycles. Multiplications can only be issued in the first slot.

\stefan{Not yet final. 64bit support and the special registers for multiply might
vanish. Maybe merge mul and mulu into the ALU Func field somehow to kill off the ALUm format?
We could keep the special register to access the high word and write the low
word into a GPR when using ALUl format, so we save one mfs per mul.
(remove this comment when multiply ISA is (somewhat) finalized)}

\clearpage
\subsection{Compare}

Applies to the ALUc and ALUci formats only. Operand \texttt{Op2}
denotes either the \texttt{Rs2}, or the \texttt{Imm}
operand. Tables~\ref{tab:cmpfunc} show the encoding of the
\texttt{func} field for the ALUc and ALUci formats.

\begin{itemize}
  \item ALUc -- Compare \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01000} &
      \bitbox{2}{\bitsunused} & \bitbox{3}{Pd} & \bitbox{5}{Rs1} & \bitbox{5}{Rs2} &
      \bitbox{3}{011} & \bitbox{4}{Func} \\
    \end{bytefield}
  \item ALUci -- Compare immediate \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01000} &
      \bitbox{2}{\bitsunused} & \bitbox{3}{Pd} & \bitbox{5}{Rs1} & \bitbox{5}{Imm} &
      \bitbox{3}{110} & \bitbox{4}{Func} \\
    \end{bytefield}
\end{itemize}

\begin{table}[hb]
  \centering
  \begin{tabular}{lll}
    \toprule
    Func & Name   & Semantics \\
    \midrule
    0000 & cmpeq  & \texttt{Pd = Rs1 ==  Op2} \\
    0001 & cmpneq & \texttt{Pd = Rs1 !=  Op2} \\
    0010 & cmplt  & \texttt{Pd = Rs1 \textless\ Op2} \\
    0011 & cmple  & \texttt{Pd = Rs1 \textless= Op2} \\
    0100 & cmpult & \texttt{Pd = Rs1 \textless\ Op2, unsigned} \\
    0101 & cmpule & \texttt{Pd = Rs1 \textless= Op2, unsigned} \\
    0110 & btest  & \texttt{Pd = (Rs1 \AND (1 \shl Op2)) != 0} \\
    0111 & ---    & unused \\
    \dots& \dots  & \dots \\
    1111 & ---    & unused \\
    \bottomrule
  \end{tabular}
  \caption{Compare functions}
  \label{tab:cmpfunc}
\end{table}

\paragraph{Pseudo Instructions}
\begin{itemize}
  \item \texttt{isodd Pd = Rs1}~\dots~\texttt{btest Pd = Rs1[r0]}
  \item \texttt{mov Pd = Rs}~\dots~\texttt{cmpneq Pd = Rs != r0}
\end{itemize}

\paragraph{Note}

The predicate register is read and written in the execute stage.

\stefan{We discussed about adding short immediate versions, but with the current predicate handling this is not
a trivial change for the compiler, so we skip that. Instead, we might introduce bez/bnez instructions, which is much more common anyway.}

\clearpage
\subsection{Predicate}

Applies to the ALUp format only, the opcodes correspond to those of
the ALU operations on general purpose
registers. Table~\ref{tab:predfunc} shows the encoding of the
\texttt{func} field for the ALUp format.

\martin{Why do we have this encoding of predicate operations with empty function
codes in-between? No need to be `compatible' with ALU operations, just makes decoding
a little bit more complex.}

\begin{itemize}
  \item ALUp -- Predicate \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01000} &
      \bitbox{2}{\bitsunused} & \bitbox{3}{Pd} & \bitbox{1}{\bitsunused} & \bitbox{4}{Ps1} & \bitbox{1}{\bitsunused} & \bitbox{4}{Ps2} &
      \bitbox{3}{100} & \bitbox{4}{Func} \\
    \end{bytefield}
\end{itemize}

\begin{table}[hb]
  \centering
  \begin{tabular}{lll}
    \toprule
    Func & Name   & Semantics \\
    \midrule
    0000 & ---    & unused \\
    \dots& \dots  & \dots \\
    0101 & ---    & unused \\
    0110 & por     & \texttt{Pd = Ps1 \OR Ps2} \\
    0111 & pand    & \texttt{Pd = Ps1 \AND Ps2} \\
    1000 & ---    & unused \\
    1001 & ---    & unused \\
    1010 & pxor    & \texttt{Pd = Ps1 \XOR Ps2} \\
    1011 & ---    & unused \\
    \dots& \dots  & \dots \\
    1111 & ---    & unused \\
    \bottomrule
  \end{tabular}
  \caption{Predicate functions}
  \label{tab:predfunc}
\end{table}

\paragraph{Pseudo Instructions}
\begin{itemize}
  \item \texttt{pmov Pd = Ps}~\dots~\texttt{por Pd = Ps \OR Ps}
  \item \texttt{pnot Pd = \NOT Ps}~\dots~\texttt{pxor Pd = (Ps \XOR p0)}
  \item \texttt{pset Pd = 1}~\dots~\texttt{por Pd = p0 \OR p0}
  \item \texttt{pclr Pd = 0}~\dots~\texttt{pxor Pd = p0 \XOR p0}
\end{itemize}

\paragraph{Note}
The predicate register is read and written in the execute stage.
All predicate combine instruction mnemonics (including pseudo instructions) are prefixed with \texttt{p},
all other instructions involving predicates are not prefixed (e.g., moving from register to predicate).

\stefan{We have a mov with two registers (\texttt{add}), mov with two predicates (\texttt{por}), a mov from register to
predicate (\texttt{cmpnez}), as well as mov from register bit to predicate (\texttt{btest}), but we are missing a
mov from predicate to register (is now a predicated set and predicated clr), and mov from predicate to register bit (is now done with
bitmasks).}

\clearpage
\subsection{Bitcopy}

Applies to the ALUb format only. The only instruction with this
encoding is \texttt{bcopy}, which is the ``inverse'' of the
\code{btest} instruction. It has the following semantics: \texttt{Rd =
  (Rs1 \AND \NOT (1 \shl Imm)) \OR (Ps \shl Imm)}\\
Note that operand \texttt{Ps}, like the source operands in the ALUp format,
can be inverted.

\begin{itemize}
  \item ALUb -- Bitcopy \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01000} &
      \bitbox{5}{Rd} & \bitbox{5}{Rs1} & \bitbox{5}{Imm} &
      \bitbox{3}{101} & \bitbox{4}{Ps} \\
    \end{bytefield}
\end{itemize}

\paragraph{Pseudo Instructions}
\begin{itemize}
  \item \texttt{mov Rd = Ps}~\dots~\texttt{bcopy Rd = r0, 0, Ps}
\end{itemize}

\paragraph{Note}
The predicate register is read in the execute stage.

\clearpage
\subsection{Move To Special}

Applies to the SPCt format only. Copy the value of a general-purpose
register to a special-purpose register. The only instruction is
\texttt{mts}, which stores the content of general-purpose register
\texttt{Rs1} in special register \texttt{Sd}.

\begin{itemize}
  \item SPCt -- Move To Special \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01001} &
      \bitbox{5}{\bitsunused} & \bitbox{5}{Rs1} & \bitbox{5}{\bitsunused} &
      \bitbox{3}{010} & \bitbox{4}{Sd} \\
    \end{bytefield}
\end{itemize}



\paragraph{Note}

\martin{\todo{We should document in which stage each special register
is read and written.}}

\clearpage
\subsection{Move From Special}

Applies to the SPCf format only. Copy the value of a special-purpose
register to a general-purpose register. The only instruction is
\texttt{mfs}, which loads the content of special register \texttt{Ss}
to general-purpose register \texttt{Rd}.

\begin{itemize}
  \item SPCf -- Move From Special \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01001} &
      \bitbox{5}{Rd} & \bitbox{10}{\bitsunused} &
      \bitbox{3}{011} & \bitbox{4}{Ss} \\
    \end{bytefield}
\end{itemize}

\clearpage
\subsection{Load Typed}
\label{subsec:load_typed}

Applies to the LDT format only. Load from a memory or
cache. In the table accesses to the stack cache are denoted by \texttt{sc}, to
the local scratchpad memory by \texttt{lm}, to the date cache by \texttt{dc},
and to the global shared memory by \texttt{gm}. All load variants are
considered to stall until the memory access is completed.

Loads incur a load-to-use latency that has to be respected by
the compiler/programmer. The result of the load is not available in
the bundle immediately after the load, i.e., there must be one bundle
between the load instruction and the first use of the destination
register. The value of the destination register is undefined during
this load delay slot.

The displacement value (\code{Imm}) value is interpreted unsigned.

\begin{itemize}
  \item LDT -- Load Typed \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01010} &
      \bitbox{5}{Rd} & \bitbox{5}{Ra} & \bitbox{5}{Type} & \bitbox{7}{Immediate} \\
    \end{bytefield}
\end{itemize}

\begin{table}[htb!]
  \centering
\begin{tabular}{lll}
  \toprule
  Type            & Name   & Semantics \\
  \midrule
  000 \textbar~00 & lws    & \texttt{Rd=sc[Ra+(Imm \shl 2)]$_{32}$} \\
  000 \textbar~01 & lwl    & \texttt{Rd=lm[Ra+(Imm \shl 2)]$_{32}$ } \\
  000 \textbar~10 & lwc    & \texttt{Rd=dc[Ra+(Imm \shl 2)]$_{32}$} \\
  000 \textbar~11 & lwm    & \texttt{Rd=gm[Ra+(Imm \shl 2)]$_{32}$} \\
  001 \textbar~00 & lhs    & \texttt{Rd=(int32\_t)sc[Ra+(Imm \shl 1)]$_{16}$} \\
  001 \textbar~01 & lhl    & \texttt{Rd=(int32\_t)lm[Ra+(Imm \shl 1)]$_{16}$ } \\
  001 \textbar~10 & lhc    & \texttt{Rd=(int32\_t)dc[Ra+(Imm \shl 1)]$_{16}$} \\
  001 \textbar~11 & lhm    & \texttt{Rd=(int32\_t)gm[Ra+(Imm \shl 1)]$_{16}$} \\
  010 \textbar~00 & lbs    & \texttt{Rd=(int32\_t)sc[Ra+Imm]$_{8}$} \\
  010 \textbar~01 & lbl    & \texttt{Rd=(int32\_t)lm[Ra+Imm]$_{8}$ } \\
  010 \textbar~10 & lbc    & \texttt{Rd=(int32\_t)dc[Ra+Imm]$_{8}$} \\
  010 \textbar~11 & lbm    & \texttt{Rd=(int32\_t)gm[Ra+Imm]$_{8}$} \\
  011 \textbar~00 & lhus   & \texttt{Rd=(uint32\_t)sc[Ra+(Imm \shl 1)]$_{16}$} \\
  011 \textbar~01 & lhul   & \texttt{Rd=(uint32\_t)lm[Ra+(Imm \shl 1)]$_{16}$ } \\
  011 \textbar~10 & lhuc   & \texttt{Rd=(uint32\_t)dc[Ra+(Imm \shl 1)]$_{16}$} \\
  011 \textbar~11 & lhum   & \texttt{Rd=(uint32\_t)gm[Ra+(Imm \shl 1)]$_{16}$} \\
  100 \textbar~00 & lbus   & \texttt{Rd=(uint32\_t)sc[Ra+Imm]$_{8}$} \\
  100 \textbar~01 & lbul   & \texttt{Rd=(uint32\_t)lm[Ra+Imm]$_{8}$ } \\
  100 \textbar~10 & lbuc   & \texttt{Rd=(uint32\_t)dc[Ra+Imm]$_{8}$} \\
  100 \textbar~11 & lbum   & \texttt{Rd=(uint32\_t)gm[Ra+Imm]$_{8}$} \\
  \cmidrule{1-3}
  101 \textbar~00 & --- & unused \\
  \dots & \dots & \dots \\
  111 \textbar~11 & --- & unused \\
  \bottomrule
\end{tabular}
\caption{Typed loads}
\label{tab:loads}
\end{table}


\martin{I don't think that (uint32\_t) does the zero extension. But I might be wrong
as my C knowledge is rusty. We should use the H\&P MIPS green card notion.}



\martin{Do we do a memory read even when the predicate is false?
Some memory locations (I/O) might have side effects on a read.
Therefore, we shall not read when the predicate is false.}



\paragraph{Note}

All loads can only be issued on the first slot.

\clearpage
\subsection{Store Typed} Applies to the STT format only. Store to a memory or
cache. In the table accesses to the stack cache are denoted by \texttt{sc}, to
the local scratchpad memory by \texttt{lm}, to the date cache by \texttt{dc},
and to the global shared memory by \texttt{gm}.

\martin{TODO: make is clear at some point that \code{gm} is basically
data cache bypass. Would be natural for I/O, but mapping I/O to \code{lm},
as it is currently in passim, is also fine.}

The displacement value (\code{Imm}) value is interpreted unsigned.
Stores can only be issued on the first slot.

\begin{itemize}
  \item STT -- Store Typed \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01011} &
      \bitbox{5}{Type} & \bitbox{5}{Ra} & \bitbox{5}{Rs} & \bitbox{7}{Offset} \\
    \end{bytefield}
\end{itemize}

\begin{table}[hb]
  \centering
\begin{tabular}{lll}
  \toprule
  Type            & Name   & Semantics \\
  \midrule
  000 \textbar~00 & sws    & \texttt{sc[Ra+(Imm \shl 2)]$_{32}$ = Rs} \\
  000 \textbar~01 & swl    & \texttt{lm[Ra+(Imm \shl 2)]$_{32}$ = Rs} \\
  000 \textbar~10 & swc    & \texttt{dc[Ra+(Imm \shl 2)]$_{32}$ = Rs} \\
  000 \textbar~11 & swm    & \texttt{gm[Ra+(Imm \shl 2)]$_{32}$ = Rs} \\
  001 \textbar~00 & shs    & \texttt{sc[Ra+(Imm \shl 1)]$_{16}$ = Rs$_{[15:0]}$} \\
  001 \textbar~01 & shl    & \texttt{lm[Ra+(Imm \shl 1)]$_{16}$ = Rs$_{[15:0]}$} \\
  001 \textbar~10 & shc    & \texttt{dc[Ra+(Imm \shl 1)]$_{16}$ = Rs$_{[15:0]}$} \\
  001 \textbar~11 & shm    & \texttt{gm[Ra+(Imm \shl 1)]$_{16}$ = Rs$_{[15:0]}$} \\
  010 \textbar~00 & sbs    & \texttt{sc[Ra+Imm]$_{8}$ = Rs$_{[7:0]}$} \\
  010 \textbar~01 & sbl    & \texttt{lm[Ra+Imm]$_{8}$ = Rs$_{[7:0]}$} \\
  010 \textbar~10 & sbc    & \texttt{dc[Ra+Imm]$_{8}$ = Rs$_{[7:0]}$} \\
  010 \textbar~11 & sbm    & \texttt{gm[Ra+Imm]$_{8}$ = Rs$_{[7:0]}$} \\
  01100 & ---   & unused \\
  \dots& \dots  & \dots \\
  11111 & ---    & unused \\
  \bottomrule
\end{tabular}
\caption{Typed stores}
\label{tab:stores}
\end{table}


\paragraph{Note - Global Memory / Data Cache}

With regard the data cache, stores are performed using a \emph{write-through}
strategy without \emph{write-allocation}. Data that is not available in the
cache will not be loaded by stores; but will be updated if it is available in
the cache.

Consistency between loads and other stores is
assumed to be guaranteed by the memory interface, i.e., memory accesses are
handled in-order with respect to a specific processor. This has implications on
the bus, the network-on-chip, and the global memory.

% TODO:
% - Arbitration of global memory

\clearpage
\subsection{Stack Control} Applies to the STC format only. Manipulate the stack
frame in the stack cache. \texttt{sres} reserves space on the stack, potentially
spilling other stack frames to main memory. \texttt{sens} ensures that a stack
frame is entirely loaded to the stack cache, or otherwise refills the stack
cache as needed. \texttt{sfree} frees space on the stack frame (without any
other side effect, i.e., no spill/fill is executed).
\texttt{sspill} writes the tail of the stack cache to main memory and updates the
spill pointer.

All immediate stack control operations are carried out assuming word
size, i.e., the immediate operand is multiplied by four. All register
operands and stack pointer addresses in special registers are in units
of bytes.

A more detailed description of the stack cache is given in
Section~\ref{sec:stack-cache}. Table~\ref{tab:stciops} shows the
encoding of operations for STCi, while Table~\ref{tab:stcrops} shows
the encoding for STCr.

\martin{This or the stack cache section shall contain pseudo code for the
  stack cache.}

\martin{TODO: There is no mentioning in load/store section that stack ld/st
use an implicit stack pointer for addressing.}

\begin{itemize}
  \item STCi -- Stack Control Immediate \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01100} &
      \bitbox{2}{Op} & \bitbox{2}{00} & \bitbox{18}{Immediate} \\
    \end{bytefield}
\end{itemize}

% TODO: more formal semantics
\begin{table}[hb]
  \centering
  \begin{tabular}{lll}
    \toprule
    Op & Name   & Semantics \\
    \midrule
    00 & sres   & Reserve space on the stack (with spill) \\
    01 & sens   & Ensure stack space (with refill) \\
    10 & sfree  & Free stack space. \\
    11 & sspill & Spill tail of the stack cache to memory \\
    \bottomrule
  \end{tabular}
  \caption{Stack control operations with immediates}
  \label{tab:stciops}
\end{table}

\begin{itemize}
  \item STCr -- Stack Control Register \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{5}{01100} &
      \bitbox{2}{Op} & \bitbox{2}{01} & \bitbox{1}{\bitsunused} & \bitbox{5}{Rs} & \bitbox{12}{\bitsunused} \\
    \end{bytefield}
\end{itemize}

% TODO: more formal semantics
\begin{table}[hb]
  \centering
  \begin{tabular}{lll}
    \toprule
    Op & Name   & Semantics \\
    \midrule
    00 & ---    & unused \\
    01 & sens   & Ensure stack space (with refill) \\
    10 & ---    & unused \\
    11 & sspill & Spill tail of the stack cache to memory \\
    \bottomrule
  \end{tabular}
  \caption{Stack control operations for registers}
  \label{tab:stcrops}
\end{table}


\paragraph{Behavior}

\texttt{sres}: Check free space left in the stack cache. Update stack-cache registers.
If needed, spill to global memory using \texttt{ss}.

\texttt{sense}: Check reserved space available in the stack cache.
If needed, refill from global memory using \texttt{ss}.

\texttt{sfree}:  Account for $\mathtt{head} - \mathtt{tail} < 0$, update
                     \texttt{ss} and \texttt{st}.
                     Update stack-cache register \texttt{head}.

\texttt{sspill}: Update \texttt{ss} and \texttt{st}.
                     Update stack-cache register \texttt{tail}.
Spill to global memory using \texttt{ss}.

\paragraph{Note}

Stack control instructions can only be issued on the first position within a
bundle.

It is permissible to use several reserve, ensure, and free operations within the
same function.


\stefan{We only need sens and sspill with registers for context-switch. Should we allow a
register version for sres and sfree as well nevertheless (I would say no)?}

\stefan{At the moment, the way it is implemented in the simulator, we have a 1-cycle hazard between
any STC instruction and a mfs, and a 1-cycle hazard between any two STC instructions, since STC
modifies the special registers in the MW stage, while mfs reads in the EX stage.
Is this the same for the hardware?

This (and all hazards for all other instructions) should be documented here in the TR explicitly, since it is a pain to debug!}

\sahar{Special registers are written/read separately. Is this 1-cycle hazard necessary? What is the reason to add it?}

\stefan{The reason for the hazards is primarily the current implementation of the simulator, there the special registers
are updated separately from the internal stack pointers, which causes the hazards. We should define how the
hardware actually behaves, and then the simulator should be updated to reflect that behavior. However, the latter is not quite trivial, I will
leave that to Florian ;) }

\clearpage
\subsection{Control-Flow Instructions}

Applies to CFLi and CFLr format only.
Transfer control to another function or perform function-local branches.
\texttt{br} performs a function-local branch.
\texttt{call} performs a function call, storing the return information
(i.e., where to resume execution when returning) in
\texttt{srb}/\texttt{sro}.
\texttt{brcf} (``branch with cache fill'') performs a global
branch. With regard to addressing modes and caching, \texttt{brcf}
behaves like a call, but it does not store any return information.
\texttt{trap} performs a system call (see Section~\ref{sec:exc}).
\texttt{ret} returns from a function, using the return information in
\texttt{srb}/\texttt{sro}.
\texttt{xret} is similar to \code{ret} but uses the return information
in \texttt{sxb}/\texttt{sxo}, which are set by interrupts, exceptions,
and traps.

With a method cache, \texttt{call}, \texttt{brfc}, \texttt{trap},
\texttt{ret}, and \texttt{xret} may cause a cache miss and a
subsequent cache refill to load the target code; they expect the size
of the code block fetched to the cache in number of bytes at
\textit{<base>-4}. \texttt{br} is assumed to be a cache hit.

Immediate call and branch instructions interpret the operand as
\emph{unsigned} for \texttt{call} and \texttt{brcf}, and as
\emph{signed} for PC-relative branches (\texttt{br}). These immediate
values are interpreted in \emph{word size}. The target address of
PC-relative branches is computed relative to the address of the branch
instruction. The immediate value for \texttt{trap} is an index into an
exception vector (see Section~\ref{sec:exc}).

Indirect call and branch instructions interpret the operand as
\emph{unsigned} absolute addresses in \emph{byte size}. Indirect
\texttt{brcf} takes two operands: a base address and an offset. The
base address is the address of the code block to be fetched; the
effective branch target is \textit{<base>+<offset>}.

The return information provided by \texttt{call} in
\texttt{srb}/\texttt{sro} should only be passed to
\texttt{ret}. Likewise, the exception return information in
\texttt{sxb}/\texttt{sxo} should only be passed to \texttt{xret}. The
unit and addressing mode of these values is implementation
dependent.\wolf{Should we keep it implementation dependent, or should
  we enforce way it is in the current implementation?}

All control-flow instructions (except \texttt{trap}) have a delayed
and a non-delayed variant. For the delayed variant, $N$
bundles following the control-flow instruction in the code are always
executed. For the non-delayed variants, the control-flow change
appears to happen immediately. However, non-delayed control-flow
instructions may require more than one cycle to be executed. The
precise timing behavior is specified along with the detailed
description of the respective instructions.

The mnemonic of an instruction's non-delayed instruction variant is
suffixed with \texttt{nd}. For clarity, this document uses the
unsuffixed name to mean both variants when describing the general
properties of the respective instruction.

\texttt{br} instructions are executed in the \texttt{EX} stage, while
the other control-flow instructions are executed in the \texttt{MEM}
stage. This corresponds to a branch delay of 2 bundles for \texttt{br}
and 3 bundles for other control-flow instructions. In case there no
other instructions available, NOP instructions can be used to fill the
delay slots. There are no restrictions with regard to the size or type
of instructions in the delay slot. The only exception is that
executing control-flow instructions in a delay slot may lead to
unspecified behavior.

\begin{table}[hb]
  \centering
  \begin{tabular}{llllll}
    \toprule
    Instruction & Immediate   & Indirect & Cache fill & Link & Delay Slots \\
    \midrule
    call        & absolute, words    & absolute, bytes        & yes        & yes  & 3 \\
    br          & PC relative, words & absolute, bytes        & no         & no   & 2 \\
    brcf        & absolute, words    & absolute+offset, bytes & yes        & no   & 3 \\
    trap        & exception vector index & ---                & yes        & no   & -- \\
    \cmidrule{1-6}
    ret         & ---         & implementation dependent      & yes        & no   & 3 \\
    xret        & ---         & implementation dependent      & yes        & no   & 3 \\
    \bottomrule
  \end{tabular}  
  \caption{Addressing modes of control-flow instructions}
  \label{tab:cfladdr}
\end{table}

\clearpage

\begin{itemize}
  \item CFLi -- Control Flow with Immediate \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{2}{10} & \bitbox{2}{Op} & \bitbox{1}{d} &
      \bitbox{22}{Immediate} \\
    \end{bytefield}
\end{itemize}

\begin{table}[hb]
  \centering
  \begin{tabular}{llll}
    \toprule
    Op & d & Name & Semantics \\
    \midrule
    00 & 0 & callnd & function call (absolute, with cache fill, non-delayed) \\
    00 & 1 & call   & delayed function call (absolute, with cache fill, delayed) \\
    01 & 0 & brnd   & local branch (PC-relative, always hit, non-delayed) \\
    01 & 1 & br     & local branch (PC-relative, always hit, delayed) \\
    10 & 0 & brcfnd & branch (absolute, with cache fill, non-delayed) \\
    10 & 1 & brcf   & branch (absolute, with cache fill, delayed) \\
    11 & 0 & trap   & system call (via exception vector, with cache fill, non-delayed) \\
    \bottomrule
  \end{tabular}
  \caption{Control-flow operations with immediate}
  \label{tab:cfliops}
\end{table}

\begin{itemize}
  \item CFLri -- Control Flow with implicit registers \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{4}{1100} & \bitbox{1}{d} &
      \bitbox{18}{\bitsunused} &
      \bitbox{2}{00} & \bitbox{2}{Op} \\
    \end{bytefield}
\end{itemize}

\begin{table}[hb]
  \centering
  \begin{tabular}{llll}
    \toprule
    Op & d & Name & Semantics \\
    \midrule
    00 & 0 & retnd  & return (with cache fill, non-delayed) \\
    00 & 1 & ret    & return (with cache fill, delayed) \\
    01 & 0 & xretnd & return from exception (with cache fill, non-delayed) \\
    01 & 1 & xret   & return from exception (with cache fill, delayed) \\
    \bottomrule
  \end{tabular}
  \caption{Control-flow operations with implicit register operands}
  \label{tab:cflriops}
\end{table}

\begin{itemize}
  \item CFLrs -- Control Flow with single registers \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{4}{1100} & \bitbox{1}{d} &
      \bitbox{5}{\bitsunused} & \bitbox{5}{Rs} & \bitbox{8}{\bitsunused} &
      \bitbox{2}{01} & \bitbox{2}{Op} \\
    \end{bytefield}
\end{itemize}

\begin{table}[hb]
  \centering
  \begin{tabular}{llll}
    \toprule
    Op & d & Name & Semantics \\
    \midrule
    00 & 0 & callnd & function call (indirect, with cache fill, non-delayed) \\
    00 & 1 & call   & function call (indirect, with cache fill, delayed) \\
    01 & 0 & brnd   & local branch (indirect, always hit, non-delayed) \\
    01 & 1 & br     & local branch (indirect, always hit, delayed) \\
    \bottomrule
  \end{tabular}
  \caption{Control-flow operations with single register operand}
  \label{tab:cflrsops}
\end{table}

\begin{itemize}
  \item CFLrt -- Control Flow with two registers \\[2ex]
    \begin{bytefield}{32}
      \bitheader{0-31} \\
      \bitbox{1}{x} & \bitbox{4}{Pred} & \bitbox{4}{1100} & \bitbox{1}{d} &
      \bitbox{5}{\bitsunused} & \bitbox{5}{Rs1} & \bitbox{5}{Rs2} & \bitbox{3}{\bitsunused} &
      \bitbox{2}{10} & \bitbox{2}{Op} \\
    \end{bytefield}
\end{itemize}

\begin{table}[ht]
  \centering
  \begin{tabular}{llll}
    \toprule
    Op & d & Name & Semantics \\
    \midrule
    10 & 0 & brcfnd & branch (indirect with offset, with cache fill, non-delayed) \\
    10 & 1 & brcf   & branch (indirect with offset, with cache fill, delayed) \\
    \bottomrule
  \end{tabular}
  \caption{Control-flow operations with two register operands}
  \label{tab:cflrtops}
\end{table}

\paragraph{Behavior -- call}

Perform a function call, filling the method cache if needed.

Listing~\ref{lst:call} shows the pseudo-code for a call. The parameter
\texttt{addr} is either an immediate value (for calls in the CFLi
format), or comes from a general-purpose register (for indirect
calls). The variables \texttt{\$srb} and \texttt{\$sro} denote the
special registers \texttt{srb} and \texttt{sro}, respectively.

First, it stores the return information, and remembers
the new base address in an internal variable. Then, it retrieves the
offset into the cache for the function to be called and if necessary
copies the instructions into the cache. Finally, it updates the
internal program counter and continues execution from there.

\begin{lstlisting}[language=C,float=h,caption={Call\label{lst:call}}]
call(addr) {
  // Store return information
  $srb = base;
  $sro = PC;
  // Remember base address
  base = addr;
  // Cache look-up and load
  coff = offset(addr);
  if (!hit(addr)) memcpy(cache[coff], mem[base], mem[base-4]);
  // Update PC
  PC = coff;
}
\end{lstlisting}

The timing of a \texttt{callnd} instruction that is executed is
equivalent to the timing of an istruction sequence \texttt{call; nop;
  nop; nop}. The timing of a \texttt{callnd} instruction with a
predicate that evaluates to \texttt{false} is equivalent to a single
\texttt{nop} instruction.

\paragraph{Behavior -- brcf}

Perform a branch, filling the method cache if needed.

The pseudo-code for a PC-relative \texttt{brcf} is shown in
Listing~\ref{lst:brcf}. It is similar to the call, but does not store
any return information. Additionally, an offset \texttt{off} may be
specified for a \texttt{brcf} in the CFLrt format; this offset is 0
for \texttt{brcf} in the CFLi format.

\begin{lstlisting}[language=C,float=h,caption={Branch with cache fill\label{lst:brcf}}]
call(addr, off) {
  // Remember base address
  base = addr;
  // Cache look-up and load
  coff = offset(addr);
  if (!hit(addr)) memcpy(cache[coff], mem[base], mem[base-4]);
  // Update PC
  PC = coff+off;
}
\end{lstlisting}

The timing of a \texttt{brcfnd} instruction that is executed is
equivalent to the timing of an istruction sequence \texttt{brcf; nop;
  nop; nop}. The timing of a \texttt{brcfnd} instruction with a
predicate that evaluates to \texttt{false} is equivalent to a single
\texttt{nop} instruction.

\paragraph{Behavior -- trap}

Perform a system call. Details are described in Section~\ref{sec:exc}.
Like the \texttt{call}, \texttt{trap} stores return information, but
it uses special registers \texttt{sxb} and \texttt{sxo} for that
purpose.

\paragraph{Behavior -- ret, xret}

Return from function call. The \texttt{ret} instruction uses the
return information in the special registers \texttt{srb}/\texttt{sro}
to compute its target address. The \texttt{xret} instruction uses the
registers \texttt{sxb}/\texttt{sxo}.

Listing~\ref{lst:return} shows the pseudo-code for \texttt{ret}. It
first retrieves the return base and does the appropriate cache
handling. It then adds the cache offset and the return offset and
assigns the sum to the internal program counter, from which execution
continues.

\begin{lstlisting}[language=C,float=h,caption={Return\label{lst:return}}]
ret() {
  // Retrieve return base
  base = $srb;
  // Cache look-up and load
  coff = offset($srb);
  if (!hit($srb)) memcpy(cache[coff], mem[base], mem[base-4]);
  // Update PC
  PC = coff+$sro;
}
\end{lstlisting}

The timing of a \texttt{retnd}/\texttt{xretnd} instruction that is
executed is equivalent to the timing of an istruction sequence
\texttt{ret; nop; nop; nop}. The timing of a
\texttt{retnd}/\texttt{xretnd} instruction with a predicate that
evaluates to \texttt{false} is equivalent to a single \texttt{nop}
instruction.

\paragraph{Behavior -- br}

Local branch, compute new program counter value and update program
counter.

The timing of a \texttt{brnd} instruction may be implementation
defined. Implementations are allowed to use branch prediction for
\texttt{brnd} instructions, if the underlying mechanism is documented
in detail. Unless specified and documented otherwise, the timing of
\texttt{brnd} must be according to ``predict-not-taken''. The timing
of a \texttt{brnd} instruction that is executed is then equivalent to
the timing of the sequence \texttt{br; nop; nop}, while the timing
with a \texttt{false} predicate is equivalent to a single
\texttt{nop}.

\paragraph{Note}

All control-flow instructions can only be issued on the first position
within a bundle.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\clearpage
\section{Exceptions: Interrupts, Faults and Traps}
\label{sec:exc}

In the following, we use \emph{exception} to denote any kind of
``abnormal'' transfer of control. \emph{Interrupts} are generated
outside of the pipeline by I/O devices. \emph{Faults} are triggered by
the pipeline for instructions that cannot be executed as expected
(accesses to unmapped memory, undecodable instructions,
etc.). \emph{Traps} are willfully generated exceptions, and are used
to invoke operating system functions.

An \emph{exception unit} that is mapped to the I/O space (see
Chapter~\ref{chap:memsyst}) is responsible for managing exceptions. It
includes the device registers shown in Table~\ref{tab:excioregs}. The
general principle of operation is that the exception unit requests the
execution of an exception from the pipeline, and the pipeline returns
an acknowledges when it starts the execution of the respective
exception handler.

The \texttt{status} register is 32 bits wide; bit 0 of that register
determines whether interrupts are enabled. They are enabled if it is
1, and they are disabled when it is zero. The \texttt{status} register
is shifted left by one bit when an exception handler is triggered, and
shifted right by one bit when returning from an exception handler via
\texttt{xret}. Overflows of the status register (which might be caused
by nested exception handlers) are silently ignored.

Internally generated exceptions, i.e., faults and traps, always take
precedence over interrupts. If more than one internal exception or
interrupt is pending at the same time, the exception with the lower
number takes precedence.

\subsection{Exception Vector}

The exception unit supports 32 exception vector entries, shown in the
lower half of Table~\ref{tab:excioregs}. Exceptions 0
and 1 are reserved for the ``illegal operation'' and ``illegal memory
access'' faults. While exceptions 2 to 15 can be used freely (e.g., by
the operating system), exceptions 16 to 32 are attached to interrupts.

\begin{table}[b]
  \centering
  \begin{tabular}{llp{.6\textwidth}}
    \toprule
    Address             & Name             & Description \\
    \midrule
    \texttt{0xf0000100} & \texttt{status} & Interrupt-enable flag \\
    \texttt{0xf0000104} & \texttt{mask} & Mask of enabled interrupts \\
    \texttt{0xf0000108} & \texttt{pend} & Pending flags for interrupts \\
    \texttt{0xf000010c} & \texttt{source} & Number of exception that
    is about to be served \\
    \texttt{0xf0000110} & \texttt{sleep} & Sleep mode (optional) \\
    \texttt{0xf0000114} & \texttt{cachectrl} & Cache control \\
    \cmidrule{1-3}
    \texttt{0xf0000180} & \texttt{vec<0>} & Address of exception handler 0, illegal operation \\
    \texttt{0xf0000184} & \texttt{vec<1>} & Address of exception handler 1, illegal memory access \\
    \dots & \dots & \dots \\
    \cmidrule{1-3}
    \texttt{0xf00001c0} & \texttt{vec<16>} & Address of exception handler 16, interrupt 0 \\
    \dots & \dots & \dots \\
    \texttt{0xf00001fc} & \texttt{vec<31>} & Address of exception handler 31, interrupt 15 \\
    \bottomrule
  \end{tabular}
  \caption{Exception unit device registers}
  \label{tab:excioregs}
\end{table}

\subsection{Traps}

The instruction \texttt{trap <n>} triggers exception number $n$. In
order to assimilate the handling of faults and traps in the pipeline,
\texttt{trap} instructions never have a delay slot. Traps can in
principle be called for any exception, e.g., to trigger an interrupt
handler from software.

\subsection{Return Information}

The return information for exceptions must be stored in registers that
are never used otherwise. Two special registers \texttt{sxb}
(\texttt{s9}) and \texttt{sxo} (\texttt{s10}) provide the return base
and return offset for exceptions. The instruction \texttt{xret}
implicitly uses these registers, as opposed to the \texttt{ret}
instruction, which uses special registers \texttt{srb} and
\texttt{sro}.

\subsection{Resuming Execution}

The return information for interrupts is set such that \texttt{xret}
returns to the bundle that was replaced by the interrupt
instruction in the pipeline.

For faults, the return information points to the bundle that triggered
the fault. After a fault, resuming execution must either have fixed
the cause of the fault and reexecute the whole bundle again, or
emulate the effects of the whole bundle (including the triggering of
further faults) and continue execution after the bundle. Due to the
complexity of the second option, we consider faults where the
respective instruction cannot be reexecuted \emph{fatal}, and advise
developers to terminate execution instead of trying to resume.

Resuming after a trap in principle has to take into account the same
considerations as faults. However, the content of the bundle is under
the control of the compiler. We require that a trap instruction is the
only instruction in a bundle. The return address for traps points to
the bundle after the one that contains the trap instruction.

\subsection{Delayed Triggering of Interrupts}

Instructions that stall the pipeline (loads, stores, calls, etc.)
delay the triggering of interrupts until the pipeline resumes
execution. Therefore, method cache fills or stack spills cannot be
interrupted. Control-flow instructions delay the triggering of
interrupts such that interrupts are never triggered inside a delay
slot or while executing instructions speculatively. Multiplications
delay the triggering of interrupts such that no multiplications are
``in flight'' when an interrupt handler is entered. Outstanding
delayed loads do not delay the triggering of interrupts. Interrupt
handlers must ensure that the contents of the special register
\texttt{sm} are saved and restored correctly.

\subsection{Sleep Mode}

The exception unit provides support for putting the processor to
sleep. Writes to the \texttt{sleep} register halt the pipeline until
an interrupt (or other exception) occurs. After executing the
respective exception handler, execution resumes after that
write. Therefore, writes to the \texttt{sleep} register should be
enclosed in a loop for continuous sleeping.

Support for sleeping is optional. On implementations that do not
support sleeping, writes to the \texttt{sleep} register are ignored
and do not have any effect. Therefore, continuing execution after a
write to the \texttt{sleep} register is not proof that an interrupt
has occurred.

\subsection{Cache Control}

The \texttt{cachectrl} register provides an interface for cache
control. Writing a value with bit 0 set invalidates the contents of
the data cache. Writing a value with bit 1 set invalidates the
contents of the method cache.

\subsection{Examples}

The API for exception and interrupt handling for Patmos is provided by
the include file \texttt{machine/exceptions.h}.

Listing~\ref{lst:excreg} shows how to register exception handlers for
specific exceptions. First, \texttt{fault\_handler} is registered as
handler for all exceptions. Then, \texttt{trap\_handler} is registered
for exception number eight, and \texttt{intr\_handler} for exceptions
16 to 19, i.e., for interrupts 0 to 3.

\begin{lstlisting}[float, caption={Exception handler registration\label{lst:excreg}}]
  for (unsigned i = 0; i < 32; i++) {
	exc_register(i, &fault_handler);
  }
  exc_register(8, &trap_handler);
  exc_register(16, &intr_handler);
  exc_register(17, &intr_handler);
  exc_register(18, &intr_handler);
  exc_register(19, &intr_handler);
\end{lstlisting}

\begin{lstlisting}[float, caption={Interrupt enabling\label{lst:intrena}}]
  // unmask interrupts
  intr_unmask_all();
  // clear pending flags
  intr_clear_all_pending();
  // enable interrupts
  intr_enable();
\end{lstlisting}

Listing~\ref{lst:intrena} shows how to enable interrupts at the start
of an application. First, all interrupts are unmasked. Then, all
pending flags are cleared to avoid triggering any ``stale''
interrupts. Finally, interrupts are enabled; after that point, Patmos
will call the respective interrupt handler when an interrupt occurs.

To unmask only certain interrupts, \texttt{machine/exceptions.h}
provides a function \texttt{intr\_unmask}, which takes an interrupt
number as parameter. Similarly, \texttt{intr\_clear\_pending} can be
used to clear only a particular pending flag. Masking interrupts can
be done through the \texttt{intr\_mask\_all} and \texttt{intr\_mask}
functions. Disabling interrupt handling in general is done with the
\texttt{intr\_disable} function.

Listing~\ref{lst:faulthandler} shows a basic fault handler. As Patmos
cannot recover from faults, the handler does not use a special
prologue, and calls \texttt{abort} at the end instead of returning. In
the function body, the handler displays the exception source on the
leds and prints a message corresponding to the type of fault that
occurred.

\begin{lstlisting}[float, caption={Fault handler example\label{lst:faulthandler}}]
void fault_handler(void) {
  unsigned source = exc_get_source();
  LEDS = source;

  const char *msg = "FAULT";
  switch(source) {
  case 0: msg = "Illegal operation"; break;
  case 1: msg = "Illegal memory access"; break;
  }
  puts(msg);

  // cannot recover from a fault
  abort();
}
\end{lstlisting}

Listing~\ref{lst:intrhandler} shows a minimal interrupt handler. It
uses the macros \texttt{exc\_prologue} and \texttt{exc\_epilogue} to
save and restore the processor state. The actual functionality is that
the state of the LEDs is incremented according to the exception source.

\begin{lstlisting}[float, caption={Interrupt handler example\label{lst:intrhandler}}]
void intr_handler(void) {
  exc_prologue();

  LEDS += exc_get_source() & 0xf;

  exc_epilogue();
}
\end{lstlisting}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\clearpage
\section{Dual Issue Instructions}

Not all instructions can be executed in both pipelines. In general, the first
pipeline implements all instructions, the second pipeline only a subset.
All memory operations are only executed in the first pipeline.

What other instructions can be executed in both pipelines is still open for
discussion and evaluation with benchmarks. A minimal approach, as first
step for the hardware implementation, is to have only ALU instructions
available in the second pipelines (excluding predicate manipulation instructions).

\stefan{From what I see in the code, it might also help a lot to allow SWS in the
second pipeline, as they are quite common. Predicate instructions are not that common
now but this will change with the new single-path passes.

This section should also talk about hazards, i.e., can we predicate the second
slot with something that we write in the first slot, what if we use a GP register
in both slots and write to it, ... }

\martin{TODO: agree that we/I should write more on this. Currently
Wolfgang has implemented ALU and predicate operations in both
pipelines. More details shall be described.}

\stefan{Is MFS/MTS allowed in both pipelines (and at the same time)? Should be helpful for prologue/epiloge code,
especially when we move return infos back to special registers.}


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Assembly Format}

\martin{This is not pasim, right?}

A VLIW instruction consists of one or two operations that are issued in the first or both pipelines.
Each operation is predicated, the predicate register is specified before the operation in parentheses \texttt{()}.
If the predicate register is prefixed by a \texttt{!}, its negation is considered.
If omitted, it defaults to \texttt{(p0)}, i.e.\ always true.

A semi-colon \texttt{;} or a newline denotes the end of an instruction or operation. If an instruction contains two operations, the operations
in the bundle must be enclosed by curly brackets. Bundles do not need to be separated by newlines or semi-colons. For bundles consisting of
only one operation, the curly brackets are optional. Labels that are prefixed by \texttt{.L} are local labels.

All register names must be prefixed by \texttt{\$}.
We use destination before source in the instructions, between destination and source a \texttt{=} character must be used instead of a comma.
Immediate values are not prefixed for decimal notation, the usual 0 and 0x formats are accepted for octal and hexadecimal immediates.
Comments start with the hash symbol \texttt{\#} and are considered to the end of the line. For memory operations, the syntax is
\texttt{[\$register + offset]}. Register or offset can be omitted, in that case the zero register \texttt{r0} or an offset of $0$ is used.

Example:
\begin{verbatim}
       # add 42 to contents of r2
       # and store result in r1 (first slot)
       { add   $r1 = $r2, $42
       # if r3 equals 50, set p1 to true
       cmpeq $p1, $r3, 50 }
       # if p1 is true, jump to label_1
 ($p1) br label_1 ; nop; nop # then wait 2 cycles
       # Load the address of a symbol into r2
       li $r2 = .L.str2
       # perform a memory store and a pred op
       { swc [$r31 + 2] = $r3 ; or $p1 = !$p2, $p3 }
       ...
label_1:
       ...
\end{verbatim}

\stefan{TODO: some words about units of .align, .size, ..; describe .fstart;
I would like to move the assembly format description out into a public repo (patmos-misc) and merge
it with a compiler usage manual, ELF file format and backend description, though.}

\subsection{Instruction Mnemonics}

The LLVM assembler supports the instructions mnemonics as specified in this document, including all pseudo instructions.

The \texttt{paasm} assembler and the \texttt{pasim} simulator use the same basic instruction mnemonic, but a \texttt{i} or
\texttt{l} suffix is appended for \emph{immediate} and \emph{long immediate} variants, while no suffix in general refers to
the register indirect variant of the instructions. As exception, the control flow instructions use a \texttt{r} suffix for the register
indirect variants and no suffix for the immediate instructions.
\stefan{This should be cleaned up, always use \texttt{i} suffix for immediates in pasim/paasm, including control flow.}

\subsection{Inline Assembly}

Inline assembly syntax is similar to GCC inline assembly. It uses \texttt{\%0}, \texttt{\%1}, \dots as placeholders
for operands. Accepted register constraints are: \texttt{r} or \texttt{R} for any general purpose register, or
\texttt{\{<registername>\}} to use a specific register.

Example:
\begin{lstlisting}
    int i, j, k;
    asm("mov  $r31 = %1  # copy i into r31\n\t"
        "add  %0 = $r5, %2"
        : "=r" (j)
        : "r" (i), "{r10}" (k));
\end{lstlisting}

\section{Configuration and Default Setup}

Various parameters of the Patmos processor can be configured to trade
space for performance. Furthermore, IO devices and memory controllers
are usually specific to FPGA boards. Those configurations are specified in
XML files and can be found at \code{patmos/hardware/config}. The base
configuration is defined in \code{default.xml}. Board specific configurations,
e.g., \code{altde2-115.xml} for the default FPGA board DE2-115 from Altera,
are specified in individual XML files.

Tabl~\ref{tab:defaults} lists the default settings for the configuration of Patmos
and the tools. \todo{Compiler and simulator settings settings are not yet updated!}

\begin{table}
\centering
\begin{tabular}{ll}
\toprule
Parameter & Default setting \\
\midrule
Main memory & 2 MB \\
Burst length & 4 words \\
Dual issue & true for uniprocessor, false for multi-processor and compiler setting \\
Method cache & 4 KB, 16 blocks \\
Data cache & 2 KB, direct mapped, write through \\
Stack cache & 2 KB \\
\bottomrule
\end{tabular}
\caption{Default settings for the Patmos hardware, the emulator, the simulator, and the compiler.}
\label{tab:defaults}
\end{table}

\chapter{Memory and I/O Subsystem}
\label{chap:memsyst}

\section{Local and Global Address Space}

The typed loads of Patmos imply two address spaces: a local address
space that is accessed through local loads and stores, and a global
address space that is accessed when using other access types. All
caches use memory that is mapped to the global address space as
backing memory. For example, the data cache fetches data from global
memory on a cache miss, and the stack cache uses global memory for
spilling and filling. Consequently, there are two memory maps, one for
the local address space and one for the global address
space. Tables~\ref{tab:lmmap} and~\ref{tab:gmmap} show the respective
address mappings. To simplify address decoding, the top four bits
(A31--A28) are generally used to distinguish between different memory
and I/O areas. The address range for I/O devices is divided further to
distinguish the different devices, as discussed in
Section~\ref{sec:iodevs}.

As \code{call}, \code{ret}, and \code{brcf} do not include memory type
information, the distinction between memory areas for these
instructions is done solely through the address mapping. The boot instruction ROM
and the instruction scratchpad memory are mapped to the lowest 128K of
the global address space. Note that this applies only to these
instructions; i.e., a \code{call} to address \code{0x00010100}
executes code that is located in the instruction scratchpad, while
non-local loads or stores to the same address access the external
SRAM. Therefore, a binary that is loaded to external memory can use
the lowest 128K of memory for data segments, but not for code
segments.

The global address space also includes a ROM and a scratchpad for
booting. The boot data ROM enables boot programs to use initialized
data segments. By copying (parts of) the boot data ROM to the boot
scratchpad, these programs can also use initialized data segments that
require write access. Note that these memory areas can be accessed by
loads and stores only; it is not possible to execute code located in
them.

\begin{table}
\centering
\begin{tabular}{ll}
\toprule
Address & Memory area \\
\midrule
\code{0x00000000}--\code{0x0000ffff} & Data Scratchpad Memory \\
\code{0x00010000}--\code{0x0001ffff} & Instruction Scratchpad Memory (write only) \\
\code{0xe0000000}--\code{0xe7ffffff} & NoC interface configuration registers \\
\code{0xe8000000}--\code{0xefffffff} & NoC communication memory \\
\code{0xf0000000}--\code{0xffffffff} & I/O devices \\
\bottomrule
\end{tabular}
\caption{Address mapping for local address space}
\label{tab:lmmap}
\end{table}

\begin{table}
\centering
\begin{tabular}{ll}
\toprule
Address & Memory area \\
\midrule
\code{0x00000000}--\code{0x0000ffff} & Boot Instruction ROM (only for code) \\
\code{0x00010000}--\code{0x0001ffff} & Instruction Scratchpad Memory (only for code) \\
\code{0x00000000}--\code{0x7fffffff} & External SRAM \\
\code{0x80000000}--\code{0x8000ffff} & Boot Data ROM (only for data) \\
\code{0x80010000}--\code{0x8001ffff} & Boot Data Scratchpad Memory (only for data) \\
\bottomrule
\end{tabular}
\caption{Address mapping for global address space}
\label{tab:gmmap}
\end{table}

\subsection{Boot Memories}

By convention, the first four words of the boot data ROM contain
information about data to be copied to the boot data scratchpad before
starting actual execution. Table~\ref{tab:bootrommap} shows the
respective data fields. Upon start, the program should copy
\code{src\_size} bytes of data from \code{src\_start} to
\code{dst\_start}. If \code{dst\_size} is greater than
\code{src\_size}, the remaining bytes are filled with zeroes.

\begin{table}
\centering
\begin{tabular}{lll}
\toprule
Address & Name & Description \\
\midrule
\code{0x80000000} & \code{src\_start} & Start address of data to be copied \\
\code{0x80000004} & \code{src\_size} & Size of data to be copied \\
\code{0x80000008} & \code{dst\_start} & Destination for copying \\
\code{0x8000000c} & \code{dst\_size} & Size of initialized data \\
\bottomrule
\end{tabular}
\caption{Boot data initialization information}
\label{tab:bootrommap}
\end{table}


\stefan{We discussed about making the stack cache memory mapped, like the SPM. The disadvantage is that
we need to reserve an additional register for the stack pointer of the stack cache. s5 (the stack cache spill pointer) must point into a main
memory address range. s6 (the stack top pointer) must point to the top of the stack cache in the cache address range and must be modifiable
(for context switching). An additional s7 must either contain the size of the stack cache or the tail pointer of the stack cache.

The advantage is we can then pass typed pointers to functions, similar to SPM pointers, if the caller stack frame is not evicted, in a first
step. As a second step, we can drop the typed loads and use the compiler to emit address range information to the WCET analysis.
A pointer into the stack cache address range is always guaranteed to be a hit (accessing an address that has been evicted is an error). We
can therefore get rid of function duplication depending on their pointer types. We basically move the information about the accessed memory from the
memory instruction to the pointer value, which can be context-sensitive.}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{I/O Devices}
\label{sec:iodevs}

Each processor contains a minimum set of standard I/O devices, such as:
processor ID, cycle counter, timer, and interrupt controller. For a minimum
communication with the outside world a processor shall be attached to a
serial port (UART). The UART represents \code{stdout}.

Within the I/O device memory area bits 19--16 are used to distinguish between different devices.
I/O device registers are mapped and aligned to 32-bit words. If a register is shorter than a word,
the upper bits shall be filled with 0 on a read. With this mapping each I/O device can have up to
16384 32-bit registers.
The I/O device base addresses for \code{pasim} are defined in \code{patmos/simulator/include/memory-map.h}
and for the compiler/library the constants are in \code{llvm/tools/clang/lib/Driver/Tools.cpp}.
\todo{Above needs to be updated as Stefan has changed it.}
The offsets of the I/O devices in the hardware are defined in the configuration XML files in
\code{patmos/hardware/config/*.xml}

In the initial prototype of Patmos we have 3 I/O devices: a system device that contains
cycle and microsecond counters, a UART for basic communication, and LEDs
on the FPGA board. One counter ticks with the clock frequency and the second
counter ticks with 1~MHz for clock frequency independent time measurements.
The counters are 64-bit values and readout of the lower word also latches the
upper word. For short measurements the lower word is usually large enough
(i.e., up to 2000~s measurements with the $\mu s$ counter) and the upper word can be ignored.
Table~\ref{tab:iomap} shows the I/O devices and the registers.

\begin{table}
\centering
\begin{tabular}{llll}
\toprule
Address & I/O Device & read & write \\
\midrule
\code{0xf0000000} & cpuinfo & processor ID & -- \\
\code{0xf0000004} & cpuinfo & clock frequency (Hz) & -- \\
\code{0xf0000008} & cpuinfo & processor count & -- \\
\code{0xf0010000} & excunit & &  \\
$\cdots$          & excunit & \multicolumn{2}{c}{Exception unit and cache control (see Section~\ref{sec:exc})} \\
\code{0xf00100ff} & excunit & & \\
\code{0xf0020000} & timer & clock cycles (high word) & cycle interrupt time (high word) \\
\code{0xf0020004} & timer & clock cycles (low word) & cycle interrupt time (low word) \\
\code{0xf0020008} & timer & time in $\mu s$ (high word) & $\mu s$ interrupt time (high word) \\
\code{0xf002000c} & timer & time in $\mu s$ (low word) &  $\mu s$ interrupt time (low word) \\
\code{0xf0080000} & UART & status & control \\
\code{0xf0080004} & UART & receive buffer & transmit buffer \\
\code{0xf0090000} & LED & -- & output register \\
\code{0xf00a0000} & Keys & input register & -- \\
\bottomrule
\end{tabular}
\caption{I/O devices and registers}
\label{tab:iomap}
\end{table}

\subsection{Timer}

The timer device provides a means to measure time as well as to
trigger an interrupt at a certain point in time. It provides two
64-bit counters. While the first counter is incremented every clock
cycle, the second counter is incremented every microsecond.

Interrupts can be triggered by storing a value in the ``cycle
interrupt time'' and ``$\mu s$ interrupt time'' registers. The timer
device will then trigger an interrupt when the respective counter
reaches the value provided in that register. The ``cycle'' interrupt
is tied to interrupt~0; the ``$\mu s$'' interrupt is tied to
interrupt~1.

To read out the 64-bit counter values consistently, the low word (at
the higher address) must be read first. This latches the high word of
the counter into an internal register, which is then returned when
reading the high word (at the lower address). Similarly, the low word
of the interrupt times must be written first. The write to the
internal 64-bit register takes effect when the high word is written.

\subsection{UART}

The UART is a minimal IO device for \texttt{stdout} and \texttt{stdin}.
It is also used for program download. Table~\ref{tab:uart} shows the
bits of the control register.

\begin{table}
\centering
\begin{tabular}{lllll}
\toprule
Bit & Status & & Control & \\
\midrule
0 & TRE & TX Transmit ready & -- & -- \\
1 & DAV & RX Data available & -- & -- \\
% 2 & PAE & RX Parity error (or EOF) & -- & -- \\
% 3 & --  & -- & TFL & TX Flush \\
\bottomrule
\end{tabular}
\caption{UART status bits} % {-- What does flush mean on a UART?}}
\label{tab:uart}
\end{table}

The UART address for \code{pasim} is defined in \code{patmos/simulator/include/uart.h}.
For the compiler/library the constant is in \code{llvm/tools/clang/lib/Driver/Tools.cpp}.

\paragraph{Proposal for CMP UART Sharing}
On a multicore system only one processor can be directly connected to the
UART. However, for debugging it would be convenient to attach several (or all)
cores to the UART. Sharing the UART can be achieved by an arbitration device
that has $n$ input ports and a simple protocol that precedes UART data by a
marker from which core the data is coming. The marker byte may be precede
each data byte or it may be distinguished by setting Bit 8. This mechanism can
also be used to represent several UARTs per core (e.g., stdout, stderr, user for SLIP,...).
\martin{The protocol shall be done in HW -- let's find a student for this.}

On the PC side a small program is needed to dispatch/demultiplex the different
data streams.

\stefan{Would be nice to be able to insert control bytes to flush the output as well, but that must be understood by the simulator as well (it
must flush its output stream).

With multiple cores writing to the UART, we need to prevent mixing up control bytes and data bytes from different cores, so I assume adding
the control bytes to is done by hardware? We could also designate one core to I/O and communicate over SPMs with the other cores, although it
adds another layer of potential bugs to the debugging process.}

\martin{Yes, the idea is that the UARTs look simple for all cores and the HW does the arbitration and additional control byte. However, no one is assigned this task :-(}

\martin{Other I/O (and using a dedicated core) is application dependent and not the topic of this report.}





\section{The Stack Cache}
\label{sec:stack-cache}

The stack cache is a processor-local, on-chip memory~\cite{patmos:stack:seus}. The stack
cache operates similar to a ring buffer. It can be seen as a stack-cache-sized
window into the main memory address range.
To manage the stack cache, we use three additional
instructions: \code{reserve}, \code{ensure},
and \code{free}. Two hardware registers define which
part of the stack area is currently in the stack cache.

\subsection{Stack Cache Manipulation}

We present the mechanics of the stack cache in C code for easier readability.
However, the hardware implementation is a synchronous design and
the algorithm is implemented by a state machine that handles
the memory spill and fill operations. In the C code following data structures are used:

\begin{description}
\item[\code{mem}] is an array representing the main memory,
\item[\code{sc}] is an array representing the stack cache,
\item[\code{m\_top}] is the register pointing to the top of the saved stack content in the main memory, and
\item[\code{sc\_top}] points to the top element in the stack cache.
\end{description}

The two pointers are full-length address registers. However,
when addressing the stack cache, only the lower $n$ bits
are used for a stack cache of a size of $2^n$ words.
The constant \code{SC\_SIZE} represents the stack
cache size and \code{SC\_MASK} is the bit mask for
the stack cache addressing. The stack cache is managed in 32-bit
words. % Therefore, the pointers count in 32-bit words.

At program start the stack cache is empty and both pointers,
\code{m\_top} and \code{sc\_top}, point to the same address,
the address that one higher as the stack area. \code{m\_top}
points to the last spilled word in main memory.
Similar, \code{sc\_top} points to the last slot in the stack
frame (top of stack). Therefore, the number of currently valid
elements in the stack cache is \code{m\_top} - \code{sc\_top}.

The compiler generates code to grow the stack downward,
as it is common for many architectures. Growing the stack downwards
has historical reasons. However, for multi-threaded
systems each thread needs a reserved, fixed memory area
for the stack and there is no benefit from growing the stack
downwards.

%We have some constants, two pointers, and main memory and the stack memory:
%\begin{figure} [!h]
%
%\begin{lstlisting}
%#define SC_SIZE 64
%#define SC_MASK (SC_SIZE-1)
%
%// The main memory
%static int mem[1024];
%// The stack cache
%static int sc[SC_SIZE];
%
%// Pointer the top memory saved stack content
%int m_top;
%
%// Pointer to the top element in the stack cache
%int sc_top;
%
%// #elements is m_top - sc_top and always has to 	be <= SC_SIZE
%\end{lstlisting}
%
% 	 \caption{Stack cache and main memory pointer definitions.}
% 	 \label{fig:sc_mem_def}
%\end{figure}

\begin{figure}
\begin{lstlisting}
void reserve(int n) {

    int nspill, i;

    sc_top -= n;
    nspill = m_top - sc_top - SC_SIZE;
    for (i=0; i<nspill; ++i) {
       --m_top;
       mem[m_top] = sc[m_top & SC_MASK];
    }
}
	\end{lstlisting}
 	 \caption{The \code{reserve} instruction provides \code{n}
	 free words in the stack cache. It may spill data into main memory.}
 	 \label{fig:res_iml}
\end{figure}


\paragraph{Reserve} The \code{reserve} instruction, as shown in Figure~\ref{fig:res_iml},
reserves space in the stack cache. Typed load and store instructions use
this reserved space. The reserve instruction may spill data to the
main memory. This spilling happens when there are not enough free words in the
stack cache to reserve the requested space.

The processor reads the number of words to be reserved
(the immediate operand of the instruction) in the decode stage.
The processor adjusts the \code{sc\_top} register in the execution
stage and also computes how many words need to be spilled in the
execution stage. The processor spills to the main memory
in the memory stage, as shown by the for loop in~Figure~\ref{fig:res_iml}.

\begin{figure}
\begin{lstlisting}
void free(int n) {

    sc_top += n;
    if (sc_top > m_top) {
        m_top = sc_top;
    }
}
\end{lstlisting}
	\caption{The \code{free} instruction drops \code{n}
	elements from the stack cache. It may change the top memory
	pointer \code{m\_top}.}
 	 \label{fig:free_iml}
\end{figure}

\paragraph{Free} The \code{free} instruction frees the reserved
space on the stack. It does not fill previously spilled data back into the stack cache.
It just changes the top of the stack pointer and may change the top of the memory
pointer, as shown in Figure~\ref{fig:free_iml}.


\begin{figure}
\begin{lstlisting}
void ensure(int n) {

    int nfill, i;

    nfill = n - (m_top - sc_top);
    for (i=0; i<nfill; ++i) {
        sc[m_top & SC_MASK] = mem[m_top];
        ++m_top;
    }
}
\end{lstlisting}
	\caption{The \code{ensure} instruction ensures that
	at least \code{n} elements are valid in the stack cache.
	It may need to fill data from main memory.}
 	\label{fig:ens_iml}
\end{figure}

\paragraph{Ensure} Returning into a function needs to ensure that the stack
frame of this function is available in the stack cache. The \code{ensure} instruction,
as shown in Figure~\ref{fig:ens_iml}, guarantees this condition.
This instruction may need to fill back the stack cache with previously spilled data.
This happens when the number of valid words in the stack cache is less than the
number of words that need to be in the stack cache.
Filling the stack cache is shown in the loop in Figure~\ref{fig:ens_iml}.

One processor register serves as stack pointer and points to the end of the stack frame.
Load and store instructions use displacement addressing relative to this stack pointer
to access the stack cache.

\begin{figure}
\begin{lstlisting}
// load one word from the stack cache
// addr is a main memory address (register value plus offset)

int load(int addr) {
    return sc[(sc_top + addr) & SC_MASK];
}

// store one word into the stack cache
// addr is a plain main memory address

void store(int addr, int val) {
    sc[(st_top + addr) & SC_MASK] = val;
}
\end{lstlisting}
	\caption{Pseudo code for the load and store instructions.}
 	\label{fig:ld_st_iml}
\end{figure}

\martin{We might update this section with more content from the S\$ paper}

As with regular ring buffers, when the size of the stack cache is not sufficient
in order to reserve additional space requested, it needs to spill some data
so far kept in the stack cache to the global memory, i.e., whenever
\code{m\_top} - \code{sc\_top} $>$ \emph{stack cache size}. A major difference,
however, is that freeing space does \emph{not} imply the reloading of data from
the global memory. When a free operation frees all stack space currently held in
the cache (or more), the special register \texttt{ss} is accordingly
incremented.

The stack cache is organized in blocks of fixed size, e.g. $32$ bytes. All
spill and fill operations are performed on the block level, while reserve, free
and ensure operations are in words.
\martin{We agreed that some size values are needed in the compiler to
generate correct code (soon). So we might bring in stack cache manipulation
in burst blocks as well.}

Addresses for load and store operations from/to the stack cache are relative to
the \code{sc\_top} pointer.

The base address for fill and spill operations of the stack cache is kept in
special register \texttt{ss}. \texttt{st} contains the address the top of the
stack cache would get if the stack cache would be fully spilled to memory.

The organization of the stack cache implies some limitations:
\begin{itemize}
  \item The maximum size of stack data accessible at any moment is limited to
        the size of the cache. The stack frame can be split, such that at any
        moment only a subset of the entire stack frame has to be resident in the
        stack cache, or a \emph{shadow} stack frame in global memory can be
        allocated.
  \item When passing pointers to data on the stack cache to other functions it
        has to be ensured that: (1) the data will be available in the cache, (2)
        the pointer is only used  with load and store operations of the stack
        cache, and (3) the relative displacement due to reserve and free
        operations on the stack is known. Alternatively, aliased stack data can
        be kept on a \emph{shadow} stack in the global memory without
        restrictions.
  \item The stack control operations only allow allocating constant-sized junks.
        Computed array sizes (C 90) and \texttt{alloca} with a computed
        allocation size have to be realized using a \emph{shadow} stack in
        global memory.
  \item The calling conventions for functions having a large number of arguments
        have to be adapted to account for the limitation of the stack cache
        size (see Section~\ref{sec:abi}).
\end{itemize}



% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Method Cache}
\label{sec:method-cache}

An overview of alternative design options with regard to the method cache can be
found in Section~\ref{sec:method_cache_options}. It is uncertain which of those
options is best, however, two candidates appear very promising and should
be evaluated: fetch on call with FIFO replacement and fetch on call with LRU
replacement. Compiler managed prefetching can still be added at a later stage.

\subsection{Common Features}

The cache is organized in blocks of a fixed size, e.g., 32 bytes.

Contiguous sequences of code are cached. These code sequences will often
correspond to entire functions. However, functions can be split into smaller
junks in order to reduce to overhead of loading the entire function at once.
Code transfers between the respective junks of the original function can be
performed using the \texttt{brcf} instruction.

A code sequence is either kept entirely in the method cache, or is entirely
purged from the cache. It is not possible to keep code sequences partially in
the cache.

Code intended for caching should be aligned in the global memory according to
the memory burst size. Call and branch instructions do not encode the size of
the target code sequence. The size is thus encoded in units of bytes right in front of the first
instruction of a code sequence that is intended for caching.
Figure~\ref{fig:cacheable_code} illustrates this convention.

\begin{figure}
  \centering
  \begin{bytefield}{25}
    \wordbox[tlr]{1}{length} \bitbox[]{1}{} \bitbox[t]{9}{burst aligned} \\
    \wordbox[tlr]{1}{first instruction}  \\
    \wordbox[tlr]{1}{second instruction} \\
    \wordbox{1}{\dots} \\
  \end{bytefield}
  \caption{Layout of code sequences intended to be cached in the method cache.}
  \label{fig:cacheable_code}
\end{figure}

The organization of the method cache implies some limitations:
\begin{itemize}
  \item The size of a code sequence intended for caching is limited to the size
        of the method cache. Splitting the function is possible.
  \item Compiler managed prefetching, if supported, has to ensure that the
        currently executed code is not purged.
\end{itemize}

% ------------------------------------------------------------------------------
\subsection{FIFO replacement}

The method cache with FIFO replacement allocates a single junk of contiguous
space for a cached code sequence. Every block in the cache is associated with a
tag, that corresponds to the base addresses of cached code sequences. However,
the tag is only set for the first block of a code sequence. The tags of all
other blocks are cleared. This simplifies the purging of cache content when
other code is fetched into the cache.

Code is fetched into the cache according to a \texttt{fifo-base} pointer, which
points to the first block of the method cache where the code will be placed.
After the fetching the code from global memory has completed this pointer is
advanced to point to the block immediately following the least recently fetched
block.

The design of the method cache with FIFO replacement is based on the
design for the Java processor JOP~\cite{jop:jtres_cache} .

% ------------------------------------------------------------------------------
\subsection{LRU replacement}

The LRU cache configuration is more complex. Code is \emph{not} kept in
contiguous blocks and might be scattered according to the LRU time stamps of the
blocks in the cache. Every block is thus tagged with the address of the block
in global memory and an LRU time stamp. The address part of the tag is need to
rediscover the block during instruction fetch. The time stamp is required to
implement the LRU policy.

In addition, the length of every code sequence currently in the cache has to be
stored.

\paragraph*{Time Stamps}
On every access to the method cache, i.e., for every call or non-cache-relative
branch, the LRU time stamps of the blocks (possibly all) in the cache has to be
done. It is important to note that \emph{all} blocks of a code sequence share
the \emph{same} LRU time stamp at all times.

\fb{The time stamps could also be stored per code sequence in the cache. This
    might simplify the implementation of the LRU policy.}

\paragraph*{Instruction Fetch}
In order to fetch an instruction from the method cache the address of the
instruction is compared with the address tag of every block in the cache
(excluding some of the least significant bits depending on the cache's block
size). If a matching tag is found, i.e., a cache hit, the respective word in the
block is fetched.

If no block with a matched tag exists, a cache miss occurs and the target block
has to be transferred from the global memory into the cache.
\martin{We have cache misses on fetch in a LRU based method cache? I don't think so.}

\paragraph*{Purging Blocks}
When a code sequence is to be loaded into the cache, it has to be ensured that
enough space is available to hold all the blocks of that code sequence by
purging some blocks currently in use. Note, again, only entire code sequences
are purged from the cache, i.e., all its blocks at once. Code sequences are
repeatedly purged until enough space becomes available in the cache.

\paragraph*{Cache Fill}
Once enough space is available, the code sequence is transferred block-wise from
global memory to the cache, the tag and LRU time stamp are set accordingly for
every fetched block.

\martin{You might all know my position on an LRU based method cache, right?
It will be a plain mess to implement and maybe an issue on the HW
side (fully associative lookup at each fetch!). However, if one would
like to go this direction, it might be an interesting experiment.
One optimization point could be instead of the full associative lookup
on each fetch to have a translation table of block addresses to cache
blocks. This might add `just' another pipeline stage into the fetch
part.}

\martin{We could also think about doing the load/replacement
in SW - more like a managed ISPM.}

\subsection{Method Cache Options}
\label{sec:method_cache_options}

We have several options to implement the method cache and related instructions
(call, return). Note, all replacement policies operate on the method/function
level.
\begin{itemize}
  \item Fetch on call, with FIFO replacement \\
        On a call it is checked whether the target method is in the cache or
        not. If yes, execution continues. Otherwise, the call instruction
        starts fetching the method into the cache, the pipeline is stalled.
  \item Fetch on call, with FILO replacement \\
        Same as above, only that the replacement strategy if FILO, i.e., like a
        stack.
  \item prefetch before call, with FILO replacement \\
        We define two instructions to perform a function call. A compiler-placed
        prefetch instructions ensure that the target method is either in the
        cache, or triggers the loading of the function. Calls merely check
        whether the method is completely loaded and transfer control.
        (FIFO replacement is not possible due to potential eviction of the
        current method executing the prefetch).
  \item prefetch before call, explicit unload, with FILO replacement \\
        Same as before, with an additional \emph{unload} instruction to evict
        methods explicitly from the cache -- i.e., to free space after as shown
        by the following example:
\begin{verbatim}
  A()
  // unload here to avoid mutual eviction
  // in loop of B and C, assuming A+B, A+C,
  // B+C fit in the cache, but not A+B+C
  while(true) {
    B() //
    C();
  }
\end{verbatim}
  \item fetch on call, LRU replacement
  \item prefetch before call, LRU replacement \\
        This is everybody's darling: compiler-placed prefetching with stalling
        call instructions. Safe, clean, and expensive in hardware ;-)
\end{itemize}

%\stefan{There are quite a few knobs that we can turn with the method cache (btw, should we call it function cache since we are compiling C
%code?)
%
%\begin{itemize}
%\item Functions or subfunctions:
%
%\item Split allocation and preloading or always load complete (sub)function:
%
%\item Allocation in hardware (FIFO) or software (FIFO, LRU,..):
%
%\item Organize in blocks or as SPM, continous function entries or allow allocation of random blocks:
%
%\item Hit detection in hardware or software:
%
%\item Separate i-cache to persist 'macros', interrupt handlers, or commonly used functions:
%
%\end{itemize}
%
%I will elaborate on this, just commiting it as it is for now.
%}


\stefan{How do we initialize the core, i.e., how do we get the initial start-up code into the i-cache, especially when
we use software-controlled i-cache allocation? How do we handle interrupts (they need to get into the cache before they can be executed)?}

\jack{This is a good use for I-SPM. Use it as an operating system ``ROM''
or at least a first-stage bootloader.}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Instruction Cache}

This section will cover a configuration of Patmos with a standard instruction cache design, i.e., without a method cache.

We would like to see a Patmos implementation with a 2-way set-associative instruction cache governed under the least-recently used (LRU) replacement policy.
This allows for a "real" comparison between a FIFO method cache and a standard instruction cache on the same architecture.

\cullmann{During the last meeting, we proposed to have a normal LRU instruction cache, not a method cache with LRU replacement.
I thought the idea was to compare the performance of a method cache with a normal cache.
Therefore we don't really see a benefit in LRU method cache but would like to see an normal instruction cache instead to allow this comparison.
}

\fb{For a reasonable comparison we still need a reasonable baseline for the
method cache. Please add a section on the standard instruction cache design,
issues you would like to see addressed there, and potential amendments to the
ISA with respect to the current proposal with a method cache. Thanks!}

\martin{Agreed that comparison between FIFO M\$ and plain I\$ is one of
the project goals. However, before doing the HW support for both I would
like to see the comparison within the WCET analysis. I think there is an
empty paper start here in this SVN under 2012/mceval/mceval.tex ;-)}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Data Cache}

This section will cover a configuration of Patmos with a standard data cache design, i.e., without a stack cache (and shadow stack).

We would like to see a Patmos implementation with a 2-way or 4-way set-associative data cache governed under the least-recently used (LRU) replacement policy.
The data cache should be write-through.

Again this allows for a "real" comparison between the stack cache and a standard data cache on the same architecture.

It might also be interesting to explore the object cache idea \cite{jop:ocache, jop:ocwcet:ccpe} where objects (heap allocated structures) are tracked via
a fully associative cache. Furthermore, for arrays with low temporal locality
a small set of prefetch buffers may benefit from spacial locality.

\section{Hardware Interface}

For the connection of Patmos to a memory controller, I/O devices, the
core-to-core network on chip, and/or the memory arbiter an interface
standard needs to be specified. Several standards are available.  We
decided to base the interface on OCP\footnote{The OCP specification is
  available at \url{http://www.accellera.org/downloads/standards/ocp/ocp_3.0/}}~\cite{ocp:spec}
and subset the standard as we need it. While we use OCP as basis for
the hardware interface of Patmos, we expressly do not claim
compliance with the OCP specification.

\subsection{Description}

\begin{figure}
  \centering
  \includegraphics[scale=.8]{fig/ocppipe}
  \caption{Localization of OCP signals in the pipeline}
  \label{fig:ocppipe}
\end{figure}

Figure~\ref{fig:ocppipe} shows the OCP signals in the Patmos
pipeline. The master signals are generated in the execute stage, and
the slave signals are captured in the memory stage.\footnote{For
  clarity, the handling of both parts is implemented in the file
  \code{Memory.scala}.}

\begin{figure}
  \centering
  \includegraphics[scale=.8]{fig/ocplevels}
  \caption{OCP levels in Patmos}
  \label{fig:ocplevels}
\end{figure}

The different variants of the OCP protocol in the scope of the Patmos
processor are shown in Figure~\ref{fig:ocplevels}.

\subsubsection{\code{OCPcore}}

The variant of OCP generated by the pipeline for the local address
space. The respective signals are shown in
Table~\ref{tab:coresignals}. \code{OCPcore} is tailored to accesses to
on-chip memories, which on FPGAs necessarily include an internal
register. To enable sub-word transfers of data, the signal
\code{MByteEn} is used. The following assumptions apply:
\begin{itemize}
\item Only reads (\code{RD}) and writes (\code{WR}) are
  supported. Writes require a response (\code{writeresp\_enable=1}),
  such that every command must be followed by a response.
\item No \code{SCmdAccept} or \code{MRespAccept}, flow control is done
  solely via \code{SResp}.
\item Slaves may generate responses earliest in the cycle after a
  command.
\item The master may issue commands in the same cycle as the slave
  sends its response, i.e., basic support for pipelining is required.
\item \code{MByteEn} is assumed to be properly aligned
  (\code{force\_aligned=1}). The signal can be ignored for read
  accesses without side-effects.
\end{itemize}

\begin{table}
  \centering
  \caption{\code{OCPcore} signals}
  \label{tab:coresignals}
  \begin{tabular}{ll}
    \toprule
    Signal & Description \\
    \midrule
    \code{MCmd} & Command \\
    \code{MAddr} & Address, byte-based, lowest two bits always 0 \\
    \code{MData} & Data for writes, 32 bits \\
    \code{MByteEn} & Byte enables for sub-word accesses, 4 bits \\
    \cmidrule{1-2}
    \code{SResp} & Response \\
    \code{SData} & Data for reads, 32 bits \\
    \bottomrule
  \end{tabular}
\end{table}

\subsubsection{\code{OCPio}}

The \code{OCPio} level is derived from the \code{OCPcore} level by
inserting a register in the master signals. It is slightly more
flexible than \code{OCPcore} and appropriate for I/O devices that do
not (or cannot) follow the semantics of \code{OCPcore}. Registering
the master signals changes the protocol as follows:
\begin{itemize}
\item Slaves may generate responses in the same cycle as they
  receive a command.
\item Commands are issued earliest in the cycle after a response (no
  pipelining).
\item \code{SCmdAccept} is supported. It is sufficient to register the
  master signals only if the currently registered command is
  \code{IDLE} or \code{SCmdAccept} is high.
\item In order to have symmetric handshaking for commands and
  responses and to facilitate clock-domain crossing, \code{OCPio} also
  includes a signal \code{MRespAccept}. An \code{OCPio} port that is
  derived directly from the pipeline's \code{OCPcore} port always
  accepts responses.
\end{itemize}

\subsubsection{\code{OCPcache}}

This OCP variant is generated for the global address space and is used
for communication between the pipeline and the caches. It is the same
as \code{OCPcore}, but includes an additional signal \code{MAddrSpace}
to specify the cache that should serve the access.

\subsubsection{\code{OCPburst}}

The caches access the external memory through bursts only;
Table~\ref{tab:burstsignals} shows the signals of the \code{OCPburst}
interface. The tie-off value for \code{MBurstLength} is 4, and
\code{MBurstSingleReq} is tied off to 1. This means that the master
supplies four data words for each write command, and the slave returns
four words for each read command. The burst length is configurable,
but might be restricted by the external memory and the external
memory controller.
\martin{I assume (hope) that the configurable burst length works.
One could try varying with the SRAM memory.} 
\wolf{Depends on how cleanly the code was written and on the
  hardware. The synchronous SRAM only supports burst lengths $\leq$4
  due to restrictions of the memory chip.}
All other burst-related signals are
tied off to their default values. This entails that the only sequence
for burst addresses is \code{INCR}. Bursts always start at an address
that is aligned to the burst size
(\code{burst\_aligned=1}). Furthermore, \code{reqdata\_together} is
set to 1, i.e., write commands and the respective first word are
issued together. Instead of the signal \code{MByteEn}, \code{OCPburst}
uses the signal \code{MDataByteEn}. This implies that partial write
transfers are fully supported, but partial read commands are
unsupported.

We assume that the master provides data for burst accesses in
consecutive cycles and that slaves can accept all burst data words
once they accept the first word. To enable handshaking for the
acceptance of the first data word, the \code{OCPburst} variant
includes the signals \code{MDataValid} and \code{SDataAccept}. As
\code{reqdata\_together} is set to 1, delaying the acceptance of data
also delays the acceptance of write commands. In order to do the same
for read commands, \code{OCPburst} also includes the signal
\code{SCmdAccept}. The signals \code{SCmdAccept} and
\code{SDataAccept} can be generated by the same logic. For the
acceptance of write commands they must be identical, otherwise at
least one of the signals can have an undefined value. We assume that
slaves return burst read data in consecutive cycles.

The first response to a read command may be given in the cycle after
the command. The response to a write command may be given earliest in
the cycle after the last data word was sent. Commands may be issued
earliest in the cycle after the last response from an earlier command
is received.
\martin{Having a write response one cycle after the last data and not
allowing a command in that cycle costs us one additional clock cycle
(in the TDM slot). Maybe it doe not matter.}
\wolf{The consensus was that it would not matter. We could change it
  if we make sure all slaves comply, the restriction was basically just
  put in to be on the safe side.}

\begin{table}
  \centering
  \caption{\code{OCPburst} signals}
  \label{tab:burstsignals}
  \begin{tabular}{ll}
    \toprule
    Signal & Description \\
    \midrule
    \code{MCmd} & Command \\
    \code{MAddr} & Address, byte-based, lowest two bits always 0 \\
    \code{MData} & Data for writes, 32 bits \\
    \code{MDataByteEn} & Byte enables for sub-word writes, 4 bits \\
    \code{MDataValid} & Signal that data is valid, 1 bit \\
    \cmidrule{1-2}
    \code{SResp} & Response \\
    \code{SData} & Data for reads, 32 bits \\
    \code{SCmdAccept} & Signal that command is accepted, 1 bit \\
    \code{SDataAccept} & Signal that data is accepted, 1 bit \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Remarks}

\code{SCmdAccept} is valid only while a command is unequal to
\code{IDLE}. Consequently, \code{SCmdAccept} must be properly
multiplexed to support multiple slaves. For handshaking via
\code{SResp}, it is sufficient to combine the responses of different
slaves with OR.

In \code{OCPcore} and \code{OCPcache}, slaves accept commands
implicitly. Asserting a command for more than one cycle corresponds to
issuing two separate commands. This is only allowed if the slave
responds in the cycle immediately after the first command. In
\code{OCPio} and \code{OCPburst}, slaves accept commands in the cycle
where they assert \code{SCmdAccept}. Continuing to assert a command in
the next cycle corresponds to a separate command. This is disallowed
in \code{OCPburst}, and allowed in \code{OCPio} only if the slave
responds immediately in the cycle where it asserts \code{SCmdAccept}.

\wolf{\code{OCPburst} currently allows neither pipelining nor
  same-cycle responses. If we want to, we can make it more like
  \code{OCPcore} or \code{OCPio}.}

The burst length is restricted to a constant which is a power of 2.
The address must be aligned. Burst data must be provided in
consecutive cycles. For reads, \code{SResp} is active during these
cycles and the number of responses must always match the burst length.
Error responses (where SResp has value \code{ERR}) may not abort the
response sequence prematurely. For a burst write, the master may have
to provide D1 for two or more cycles if \code{SDataAccept} is not
active in the first cycle of the transaction.

As the first data word must be accepted together with the command and
we require burst data to be provided in consecutive cycles, the
signals \code{MDataValid} and \code{SDataAccept} may appear to be
superfluous. However, they are required by the OCP standard for the
inclusion of the \code{MDataByteEn} signal, which provides separate
byte enables for each word in a burst transaction.

\martin{Burst: Is it legal (in our OCP subset) that SCmdAccept comes earlier than SDataAccept?} \wolf{No. Masters can assume that both signals are asserted in the same cycle.}

\martin{Burst: we said that we do not support pipelined requests in burst mode.
So when the slave sets SResp we are not allowing the master to initiate the next
request in the same cycle. Right?} \wolf{Right.}

\clearpage
\subsection{Timing Diagrams}

\subsubsection{\code{OCPcore}}

Figure~\ref{fig:timing_core} shows a sequence read/write/read in
\code{OCPcore}, where the slave delays the response to the write by
one cycle.

\begin{figure}
\centering
\includegraphics{fig/timing_core}
\caption{Timing diagram for \code{OCPcore}}
\label{fig:timing_core}
\end{figure}

\begin{enumerate}[A:]
\item The master issues a read by setting \code{MCmd} to \code{RD},
  \code{MAddr} to \code{A$_1$} and \code{MByteEn} to \code{E$_1$}.
\item The slave responds to the read issued in cycle A by setting
  \code{SResp} to \code{DVA} and returning the appropriate data. The
  master can issue the next command in the same cycle as it receives
  the response and issues a write command \code{WR}. The
  master provides the byte enable value \code{E$_2$} along with the
  data \code{D$_2$} to specify which bytes should be actually written.
\item The slave does not respond immediately and the master is
  stalled. \code{MCmd} must be \code{IDLE} while the master is
  stalled.
\item The slave responds to the write issued in cycle B. The master
  issues a read in the same cycle.
\item The slave responds to the read issued in cycle D.
\end{enumerate}

\clearpage
\subsubsection{\code{OCPio}}

Figure~\ref{fig:timing_io} shows a sequence read/write/read in
\code{OCPio}, where the slave does not accept the write immediately
and delays the response to the write by one cycle.

\begin{figure}
\centering
\includegraphics{fig/timing_io}
\caption{Timing diagram for \code{OCPio}}
\label{fig:timing_io}
\end{figure}

\begin{enumerate}[A:]
\item The master issues a read by setting \code{MCmd} to
  \code{RD}. The slave accepts the command by setting
  \code{SCmdAccept} to high and responds immediately by setting
  \code{SResp} to \code{DVA} and returning the appropriate data.
\item The master issues a write command \code{WR} with
  data \code{D$_2$} and byte enables \code{E$_2$}. The slave
  signals that it does not accept the command by setting
  \code{SCmdAccept} to low.
\item As the slave did not accept the command in cycle B, the master
  still issues the command. The slave accepts the command by setting
  \code{SCmdAccept} to high.
\item The slave responds to the write it accepted in cycle C. Note
  that a) the master is not allowed to issue a new command immediately
  and b) \code{SCmdAccept} may take any value, because \code{MCmd} is
  \code{IDLE}.
\item The master issues a read to which the slave responds immediately.
\end{enumerate}

\clearpage
\subsubsection{\code{OCPburst}}

Figure~\ref{fig:timing_burst} shows a read followed by a write in
\code{OCPburst}, were the slave does not accept the first data word
immediately.

\begin{figure}
\centering
\includegraphics{fig/timing_burst}
\caption{Timing diagram for \code{OCPburst}}
\label{fig:timing_burst}
\end{figure}

\begin{enumerate}[A:]
\item The master issues a read command by setting \code{MCmd} to
  \code{RD}. The slave accepts by asserting \code{SCmdAccept}.
\item The slave provides the first response \code{DVA$_{1.0}$}, with
  data from address \code{A$_1$}.
\item The slave provides the second response \code{DVA$_{1.1}$}, with
  data from address \code{A$_1$+4}.
\item The slave provides the third response \code{DVA$_{1.2}$}, with
  data from address \code{A$_1$+8}.
\item The slave provides the fourth and last response
  \code{DVA$_{1.3}$}, with data from address \code{A$_1$+12}.
\item The master issues a write command by setting \code{MCmd} to
  \code{WR} and provides the first data word \code{D$_{2.0}$} width
  byte enables \code{E$_{2.0}$} It signals that the data is valid by
  asserting \code{MDataValid}. The slave signals that it cannot accept
  the data by setting \code{SDataAccept} to low.
\item As the slave did not accept the data in cycle F, the master
  keeps issuing the command and providing the data word
  \code{D$_{2.0}$}. The slave now accepts the data by setting
  \code{SDataAccept} to high.
\item The master provides the second data word, \code{D$_{2.1}$} with
  byte enables \code{E$_{2.1}$}.
\item The master provides the third data word, \code{D$_{2.2}$} with
  byte enables \code{E$_{2.2}$}.
\item The master provides the fourth and last data word,
  \code{D$_{2.3}$} with byte enables \code{E$_{2.3}$}.
\item The slave responds to the write burst by setting \code{SResp} to
  \code{DVA}.
\end{enumerate}


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\chapter{Application Binary Interface}
\label{sec:abi}

\input{abi}


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\chapter{Implementation}

\martin{This sections shall describe implementation details,
decisions, and options.}

After a first implementation of Patmos in VHDL we did a cleanup and
rewrite in a the hardware description language Chisel~\cite{chisel:dac2012}.
The following notes on the implementation of Patmos and implementation
decisions is based on first design discussions within the VHDL version
and concrete implementation experiments with Chisel. All size and frequency
numbers are from the Chisel implementation. A comparison between VHDL
and Chisel would be of great interest.

For a comparison between Chisel and VHDL we take a snapshot when both
versions where about at the same functionality: LoC, excluding the copyright
header at 6.4.2013: Chisel: 996 VHDL: 3020. However, the VHDL code was
written quite verbatim and more usage of \code{record} would probably result
in about 2000 L0C. Still Chisel is more compact and probably easier readable.


\section{Component Organization and Pipeline Structure}

The architecture of Patmos is structured around five components, each
representing one pipeline stage. Each component contains the \emph{left}
pipeline register. E.g., the output of the \code{DEC} stage (decode signals,
the two register values, and the immediate field) is combinatorial from
the decode stage and registered in the \code{EX} stage. The motivation of
this organization is that input registers of on-chip memory elements (e.g., instruction
memory, register file, and data memory) are part of the pipeline register.
They need to be fed unconditionally from the unregistered output of
the former stage.

Each stage has exactly one pipeline register, which is placed at the begin
of the component. The pipeline registers use an enable for stalling.
Register that have no enable (input registers of on-chip memories) need
a \emph{shadow} register and a multiplexer for stalls.

The interface from the EX stage to the MEM stage might use one
field for ALU results and the store data or individual fields. Individual
fields might reduce the pressure on the ALU multiplexers.
\martin{Update to the current implementation -- check for difference.}


\section{Register File}

There are two options to implement the register file (RF) in an FPGA: (1) use
two on-chip memories to provide two read ports and one write port, or (2)
use dedicated registers and larger multiplexer structures for the read
ports. Usually one aims to use on-chip memory for the RF. However,
in a design constraint largely by the available amount of on-chip memory,
a RF built out of registers might be preferable.

For a dual issue pipeline we need 4 read ports and 2 write ports into the RF.
We explored double clocking of a on-chip based RF in~\cite{patmos:ppes2011}.
It is feasible, the resulting maximum frequency fits for the ALU path, but feels
a little bit brittle. A RF from registers might give a more robust design for the
two write ports. Furthermore, Chisel does not provide the possibility to use
more than one clock.

The ideal solution would be to make it configurable if on-chip memory or
LCs are used. The issue width should also be configurable.




\section{Resource and Fmax Numbers}

State 13.3.2013 with Chisel and DE2-70: A shared field (for EX to MEM?) results 3435 LCs
and 81.7 MHz, two fields in 3499 LCs and 81.8 MHz. Looks like not a big deal,
but just 64 more LCs. Where does this cost come from? A very inefficient
enable on the pipeline register (MUX instead of an enable signal?).

\martin{Update with reduced ALU muxes and also with additional second
ALU pipeline (forwarding). Is dual issue configurable?}

\section{ALU Discussion}

The large multiplexers and the forwarding limit the maximum frequency.
We have already removed the expensive rotate instructions and the
\code{abs} instruction.

Current version (4.4.2013) with all ALU operations and test case ALU.s
for the DE2-70 is: 3415 LCs, 85.44 MHz. Dropping \code{rsub} and all unary
ALU operations: 3173 LCs, 91.91 MHz.

\todo{This should be updated. Maybe even with some statistics how the size
(and performance ?) changed over time.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Build Instructions}
\label{ch:build_instructions}

In the following we present the Patmos build instructions on a 32-bit Linux/Ubuntu
system (14.04 LTS).%\footnote{I used the 32-bit version of Ubuntu to simplify the Quartus installation.}
The installation instructions might also be valid on different Ubuntu versions.
Patmos and the compiler have also been successfully installed on a Mac OSX
system.  The support of Windows is marginal, or basically not existent.


% ------------------------------------------------------------------------------
%\section{Prerequisites}
%
%In order to build all tools, the following programs and libraries are required:
%
%\begin{itemize}
%\item[cmake, make] \hfill\\
%The CMake (at least version 2.8) and \texttt{make} build systems are required to build the
%various components of the tool chain, such as the \texttt{clang} compiler or the \texttt{compiler-rt} system library.
%\medskip
%
%\item[gcc, g++] \hfill\\
%A C and C++ compiler such as GCC is required to build \texttt{clang}, \texttt{llvm}
%and \texttt{gold}. It is also possible to use a separate \texttt{clang} installation as
%an alternative to GCC. Compiling with \texttt{clang} will result in shorter compile
%times, but at least version 3.3 is required.
%\medskip
%
%\item[flex, bison, texinfo] \hfill\\
%These tools are required to build tools such as gold successfully.
%\medskip
%
%\item[libelf] \hfill\\
%The tools in the Patmos tool chain require the development headers of \texttt{libelf},
%as this library is used to read and write ELF files.
%\medskip
%
%\item[boost] \hfill\\
%The simulator requires the program-options library from the \texttt{boost} C++ library
%(at least version 1.46).
%\medskip
%
%\item[git, subversion] \hfill\\
%The version control system \texttt{git} and \texttt{svn} are required
%to download the latest development versions of the tools and the benchmarks.
%\end{itemize}
%


\section{Setup On Ubuntu 14.04 LTS}

After a plain Ubuntu installation several packages need to be installed.
The following apt-get lists the packages that need to be
installed:\footnote{Some packages might be available in newer version
when reading this document.}

\begin{verbatim}
sudo apt-get install git openjdk-7-jdk gitk cmake make g++ texinfo flex bison \
  subversion libelf-dev graphviz libboost-dev libboost-program-options-dev ruby1.9.1 \
  ruby1.9.1-dev liblpsolve55-dev python zlib1g-dev gtkwave gtkterm scala
\end{verbatim}

\emph{The following gem install might not be needed as with the correct
packages (liblpsolve55-dev) the setup script shall do it automatically.
Needs to be checked on a fresh Ubuntu machine.
This is done after T-CREST has been installed.}

From within \code{llvm/tools/platin} install:

\begin{verbatim}
sudo gem1.9.1 install lpsolve --pre
sudo gem1.9.1 install ext/lpsolve-5.5.10.j.gem
\end{verbatim}

Install \code{sbt} with:

\begin{verbatim}
wget http://dl.bintray.com/sbt/debian/sbt-0.13.2.deb
sudo dpkg -i sbt-0.13.2.deb
sudo apt-get update
sudo apt-get install sbt
\end{verbatim}

For the Quartus setup it is best to change the default shall to \code{/bin/bash}:

\begin{verbatim}
sudo rm /bin/sh
sudo ln -s /bin/bash /bin/sh
\end{verbatim}


\subsection{Building Patmos and the Compiler Tool Chain}
\label{sec:build:compiler}

We assume that the T-CREST project will live in \code{\$HOME/t-crest}.
Before building Patmos add the path
to the compiler executables (e.g., into your \code{.bashrc} or
\code{.profile}):\footnote{The path needs to be absolute. LLVM cannot handle
a path relative to the home folder \textasciitilde{}, e.g., \code{\textasciitilde{}/t-crest/local/bin}.}

\begin{verbatim}
export PATH=$PATH:$HOME/t-crest/local/bin
\end{verbatim}

A complete logout from Ubuntu might be needed to take effect (just closing
a terminal window is not enough, depending on how you set up your profile files).

Patmos and the compiler can be checked out from GitHub and built as follows:

\begin{verbatim}
mkdir ~/t-crest
cd ~/t-crest
git clone https://github.com/t-crest/patmos-misc.git misc
./misc/build.sh
\end{verbatim}


For developers with push permission generate an ssh key and upload
it at GitHub (see \url{https://help.github.com/articles/generating-ssh-keys}
for detailed instructions).
The ssh based clone string for write access is then:

\begin{verbatim}
git clone git@github.com:t-crest/patmos-misc.git misc
./misc/build.sh
\end{verbatim}

This script (\code{build.sh}) will checkout several other repositories (the compiler, library,
and the Patmos source) and
builds the compiler and the Patmos simulator.
Therefore, take a cup of coffee and find some nice reading.

You can test your installation by checking if the compiler is available:

\begin{verbatim}
patmos-clang --version
\end{verbatim}

The \code{build.sh} script contains default options, which should work out of the box. 
The build settings can be changed by a customized \code{misc/build.cfg} file. The file \code{misc/build.cfg.dist}
is an example configuration file containing default values. It is ignored by the build process and should not be
edited.\footnote{It is autogenerated by \code{build.sh -e} from the values in \code{build.sh}.}
To change any options for \code{misc/build.sh}, either start with an empty \code{misc/build.cfg} or
copy \code{misc/build.cfg.dist} and modify the values to your need.


\martin{In Mac OS X I have only .profile and I don't understand what the issue by 'only read by login terminals'.}
\stefan{Login shells are only opened at logins. Interactive terminals are all terminals that are opened by your window manager or
other means. This is why you need to reboot to have .profile take effect. There are slight differences between bash and zsh when which file is read, 
and distribution further mix up the files in non-standard ways.}

\stefan{Relative paths should actually work, but the \textasciitilde{} shortcut is shell-specific and may not work, but
not sure about this.}


For correct correct signing of your changes set the username and
email in git with:

\begin{verbatim}
git config --global user.name "Joe Someone"
git config --global user.email "joe.someone@domain.com"
\end{verbatim}

Optionally, you may additionally add the \code{misc} checkout to your path, so that \code{build.sh} and the helper tools in 
\code{misc} can be executed from everywhere.

\begin{verbatim}
export PATH=$PATH:$HOME/t-crest/misc
\end{verbatim}


\subsection{Quartus}

Download the free web edition of Quartus from Altera.\footnote{For a 32-bit Linux you need to
use Quartus 13.x as 32-bit support has been dropped from Quartus 14.x.}
The Linux version is
installed as follows:\footnote{\url{http://www.altera.com/literature/manual/quartus_install.pdf}}

\begin{verbatim}
tar xvf Quartus-web-xxx.tar
\end{verbatim}

The software installation is started with:

\begin{verbatim}
bash setup.sh
\end{verbatim}

Then add the bin directory of Quartus to your \$PATH.
%
For access to the serial port and access rights for the USB Blaster following additional steps are needed:

\begin{verbatim}
# Add user to dialout group for the serial port access
sudo usermod -a -G dialout user
\end{verbatim}

Add permissions to access the Altera USB Blaster by creating or editing \code{/etc/udev/rules.d/51-usbblaster.rules}:
%sudo su -
%echo "SUBSYSTEM==\"usb\", DRIVER==\"usb\", ATTR{idVendor}==\"09fb\", \
%ATTR{idProduct}==\"6001\", MODE=\"0666\"" > /etc/udev/rules.d/51-usbblaster.rules

\begin{verbatim}
# From the 32-bit installation:
SUBSYSTEM=="usb", DRIVER=="usb", ATTR{idVendor}=="09fb", ATTR{idProduct}=="6001", MODE="0666"

# USB-Blaster
BUS=="usb", SYSFS{idVendor}=="09fb", SYSFS{idProduct}=="6001", MODE="0666"
BUS=="usb", SYSFS{idVendor}=="09fb", SYSFS{idProduct}=="6002", MODE="0666"
BUS=="usb", SYSFS{idVendor}=="09fb", SYSFS{idProduct}=="6003", MODE="0666"

# USB-Blaster II
BUS=="usb", SYSFS{idVendor}=="09fb", SYSFS{idProduct}=="6010", MODE="0666"
BUS=="usb", SYSFS{idVendor}=="09fb", SYSFS{idProduct}=="6810", MODE="0666"
\end{verbatim}

Reload the rules:
\begin{verbatim}
sudo udevadm control --reload-rules
\end{verbatim}

After fixing the permissions for the USB Blaster open Quartus and test if the
cable is found with the programmer. Select USB-Blaster in \emph{Hardware Setup}.
When connected to an FPGA test the USB-Blaster with \emph{Auto Detect}
(With the DE2-115, a question about shared JTAG ID pops up -- select EP4CE115).

Quartus~13.1 drops the support of Cyclone~II devices. Therefore, the
(phased out) Altera DE2-70 board is not supported anymore. Version 13.0 supports Cyclone~II\
till Cyclone~V devices and might be the best option at the moment.

\section{Setup On Mac OS X}

First install the Mac compiler (Xcode) and the command line tools.

This subsection describes the installation of needed tools and libraries
on Mac OS X. It is based on a OS X Yosemite and assumes to use
homebrew\footnote{\url{http://brew.sh/}} for package management.

For the build of Patmos and the compiler we need:

\begin{verbatim}
brew install cmake boost libelf sbt doxygen
\end{verbatim}

Mac OS X comes with Python version 2.7 preinstalled. For Aegean
we need Python 3 and the xml library that can be installed with:

\begin{verbatim}
brew install python3
pip3 install lxml
\end{verbatim}

For wave viewing install GTKWave with

\begin{verbatim}
brew install homebrew/x11/gtkwave
\end{verbatim}

\todo{The following should probably be deleted as we switched to homebrew for the setup.}

Several tools are needed, best installed with MacPorts. For Patmos simulator and assembler:
\code{boost}, \code{libelf}.
For simulation with ModelSim: \code{wine}
For Aegean: \code{python33}, \code{py33-lxml}. Make a link from \code{python3} to \code{python3.3} as this is the way it is invoked.
\todo{Alex suggested a way to avoid this by querying how to invoke python.}

\section{Hello World}

We can start with the standard, harmless looking Hello
World:\footnote{This example code is not part of the distribution, but
can be put at any directory.}
\begin{lstlisting}
int main() {
    printf("Hello Patmos!\n");
}
\end{lstlisting}

With the compiler installed it can be compiled to a Patmos executable
and run with the simulator as follows:

\begin{verbatim}
patmos-clang hello.c
pasim a.out
\end{verbatim}

However, this innocent examples is quiet challenging for an embedded system:
It needs a C compiler, an implementation of the standard C library, printf
itself is a challenging function, the generated ELF file needs to be understood
by a tool and the individual sections downloaded, and finally a terminal (often
a serial line) needs to be available on the target, and your test PC needs to
have a serial line as well and a terminal program needs to run.

Therefore, we might start from a minimal assembler program and execute
that in the simulator and emulator. From that base we can build up too
a multi-core version of Patmos that executes in an FPGA and bootstraps
with programs loaded via a serial port.


\section{Building Patmos}

The whole build process of Patmos,%
\footnote{Get the source from GitHub with: \code{git clone git@github.com:t-crest/patmos}}
applications in assembler
and in C, configuration of the FPGA, and downloading an application
is \code{Makefile} based. The build of Patmos is within the \code{patmos} folder,
therefore, the following descriptions assumes you have changed to:

\begin{verbatim}
    t-crest/patmos
\end{verbatim}


The complete design flow (including the LLVM
based C compiler) can execute in a Linux machine. The flow without
the C compiler should be able to execute in a Windows/Cygwin environment.
Under Mac OS X all tools, except Quartus, are working (ModelSim under
wine). For FPGA synthesis and configuration Windows XP within a VMWare
virtual machine is a possible solution.

On a Linux box with the installed LLVM compiler and Quartus in your PATH,
the complete build processes for a Hello World is as follows:

\begin{verbatim}
make BOOTAPP=bootable-bootloader APP=hello_puts \
   tools comp gen synth config download
\end{verbatim}

However, this involves quite many steps. Therefore, we suggest doing some \emph{manual}
buildup to explore the full build process and the possibilities.

As a start we build some tools (e.g., the assembler, simulator, file conversion
utility, and the boot loader). This has to be done once only.

\begin{verbatim}
make tools
\end{verbatim}

\subsection{A Few Assembler Instructions}

We start with a very small assembler program that moves a few values into registers
(see \code{asm/basic.s}). With following make command the program is assembled
and executed in the software simulator of Patmos.

\begin{verbatim}
make swsim BOOTAPP=basic
\end{verbatim}

The simulator options are set to write out the register contents after each instruction.
The emulator (the Chisel based simulator) can execute the same program
with following command:

\begin{verbatim}
make hwsim BOOTAPP=basic
\end{verbatim}

This command assembles the application, executes the Chisel based hardware
construction during which the program is used to initialize the on-chip ROM,
generates a C++ based emulator, compiles that emulator, and executes it.
The emulator shows the register content after each instruction.

Those two Patmos simulations, the software simulator and the Chisel based emulator,
are used for a co-simulation based test. In this co-simulation all available assembler
programs are executed in both simulations and the register out put is compared.
The test can be started with:

\begin{verbatim}
make test
\end{verbatim}


\todo{ModelSim simulation}

\subsection{We Can Blink in Assembler}

\todo{write}

\subsection{A C Based Blinking LED}

As a first real example we build the embedded version of Hello World, the
blinking LED, from a C program. You can find the C source in \code{c/blinking.c}.

\begin{verbatim}
make BOOTAPP=bootable-blinking comp gen synth config
\end{verbatim}

Additionally to blinking an LED this program also writes alternating `0' and `1'
to the serial port. Connect the FPGA board to your serial port,
open a terminal of your choice (e.g., \code{gtkterm}), connect to the serial port,
set the baud rate to 115200, no parity, and no handshaking.
You should see alternating `0' and `1' sent out synchronous to the blinking.

Note that the program name (\code{blink}) is prefixed by \code{bootable-}.
The marker selects the right compiler settings for a program that ends up in
the Patmos on-chip ROM. As the on-chip memory is limited, only tiny programs
are supported in this execution mode.

Figure~\ref{fig:blink} shows the code for the embedded Hello World
C program. Two constants (0xF0090000 and 0xF0080004) are the addresses
of the IO devices LED and serial port. IO devices connected to Patmos are
connected to the local, uncached memory area. This is the same memory
area where data SPM and NoC SPM are connected. Therefore, to access them
one needs to use the local load/store instructions. With the attribute \code{\_SPM}
the compiler is instructed to emit the correct load and store instructions.

\begin{lstlisting}[float,caption={A blinking LED\label{fig:blink}}]
/*
    This is a minimal C program executed on the FPGA version of Patmos.
    An embedded Hello World program: a blinking LED.

    Additional to the blinking LED we write to the UART '0' and '1' (if available).

    Author: Martin Schoeberl
    Copyright: DTU, BSD License
*/

#include <machine/spm.h>

int main() {

    volatile _SPM int *led_ptr  = (volatile _SPM int *) 0xF0090000;
    volatile _SPM int *uart_ptr = (volatile _SPM int *) 0xF0080004;
    int i, j;

    for (;;) {
        *uart_ptr = '1';
        for (i=2000; i!=0; --i)
            for (j=2000; j!=0; --j)
                *led_ptr = 1;


        *uart_ptr = '0';
        for (i=2000; i!=0; --i)
            for (j=2000; j!=0; --j)
                *led_ptr = 0;

    }
}
\end{lstlisting}

\martin{TODO: we need to streamline the make process a little bit.
The targets might be a little bit confusing. Patmos is compiled two times.}


\subsection{Make Targets}

A list of the most important make targets:

\begin{description}
\item[tools] build of all tools, including the Patmos software simulator
\item[asm] assemble source (from folder \code{asm})
\item[swsim] execute the Patmos simulator
\item[hwsim] execute the Patmos emulator
\item[emulator] build the Chisel based C++ emulator
\item[comp] compile a C program as loadable ELF binary
\item[bootcomp] compile a C program as a bootable image
\item[gen] generate the Verilog code
\item[synth] synthesize for an FPGA
\item[config] configure the FPGA
\item[download] download an elf file into the main memory via the Patmos bootloader
\item[test] run all assembler tests 
\end{description}

The name of an application that can execute from the on-chip ROM is set
with the BOOTAPP variable.

\subsection{Download of ELF Files}
\label{sec:elf:files}

On a Linux box with the installed LLVM compiler and Quartus in your PATH,
the complete build processes for the Hello World is as follows:

% make BOOTAPP=bootable-bootloader APP=hello_puts tools synth comp config download
\begin{verbatim}
make BOOTAPP=bootable-bootloader APP=hello_puts \
   tools comp gen synth config download
\end{verbatim}

You should see the download information and then the greeting from Patmos:

\begin{verbatim}
/home/martin/t-crest/patmos/install/bin/patserdow -v /dev/ttyUSB0 /home/martin/t-crest/patmos/tmp/hello_puts.elf
Port opened: true
Params set: true
Elf version is '1':true
CPU type is:48875
Instruction width is 32 bits:true
Is Big Endian:true
File is of type exe:true
Entry point:131076

[++++++++++] 49778/49778 bytes
Hello, World!

EXIT 0
\end{verbatim}

The \code{Makefile} use following variables to configure the build process:
\code{BOOTAPP} is an application that ends in the on-chip ROM. This may
be an assembler program or a simple C program;
most prominent the boot loader for ELF binaries.
A C program that shall be compiled as ROM target needs to be prefixed
with \code{bootable-}.
\code{APP} is a C program resulting in an ELF binary that can be either
loaded by the emulator or the boot loader when executing in an FPGA.
% TODO: test and talk about patsim. Having a complete ELF in the FPGA
% without the boot loader would be nice as well.

When the FPGA configuration (the Patmos hardware) is stable and only
the C application shall be recompiled and downloaded execute:

\begin{verbatim}
make BOOTAPP=bootable-bootloader APP=hello_puts comp config download
\end{verbatim}

Here an example of the individual steps to build the blinking LED C
hello world (on a different FPGA board):
\begin{verbatim}
make tools
make BOOTAPP=bootable-echo bootcomp gen
make BOOTAPP=bootable-echo BOARD=bemicro synth
make BOARD=bemicro BLASTER_TYPE=Arrow-USB-Blaster config
\end{verbatim}

This split of the make commands is for demonstration. It is
possible to merge all steps into a single make (on Linux
systems) or two steps when using two operating
systems (e.g., Mac OSX for compilation and Windows for synthesis).

\paragraph{Emulator and elf File}

The emulator can read a standard ELF file. An example how to compile
a small C program that uses part of the standard library and executing
it on the emulator is as follows:

\begin{verbatim}
make emulator
make comp APP=hello_puts
install/bin/emulator tmp/hello_puts.elf
\end{verbatim}

\martin{Where is the make target to run the emulator with an ELF file?}

\subsection{Supported FPGA Boards}

At the time of this writing we have mainly focused on Altera FPGA based boards. Following boards
are directly supported in the build process:

\begin{itemize}
\item Altera DE2-115 (\code{altde2-115}), this is the default board for the project
\item Altera DE2-70 (\code{altde2-70})
\item Altera/Farnell BeMicro (\code{bemicro})
\end{itemize}

Setting the \code{BOARD} variable configures the board that shall be used.
Without changing the \code{Makefile} the default of the board (and any other build variables)
can be overridden by providing a local \code{config.mk} that is included in the \code{Makefile}.

\subsection{Multicore Patmos}

A multicore Patmos with shared external memory and the network-on-chip Argo is configured via
the Aegean framework. Aegean is a collection of Python scripts that read in XML based configuration
description (e.g., topology, network connections, processor types,...). Aegean generates the Chisel based
components (Partmos, memory arbitration tree, and memory controller), generates the VHDL top-level
to connect them with the VHDL based NoC, synthesizes the hardware, compiles the application for the
individual cores, configures the FPGA, and downloads the application.

In directory \code{aegean} run:

\begin{verbatim}
make platform AEGEAN_PLATFORM=mandelbrot_demo
make synth config AEGEAN_PLATFORM=mandelbrot_demo
\end{verbatim}

to generate (and synthesize) the mandelbrot application on a 4 core
version of Patmos for an Altera DE2-115 FPGA board. This application is compiled
into the on-chip memories and therefore executing right after configuration of the
FPGA. Have a terminal open and connected to the serial port (115200 baud, 1 stop bit,
no handshake) during and after the FPGA configuration and you shall see the output of
the mandelbrot calculation.

However, the approach to have the application in on-chip memory works for tiny programs
only. Furthermore, each software change needs a new synthesize run. A better approach is
to build a platform that contains a bootloader (similar to the single core version) and some
startup code to synchronize the program start with the other cores. This platform is the default
configuration in Aegean and needs to be generated only once with:

\begin{verbatim}
make platform
make synth
\end{verbatim}

The FPGA is configured from within the \code{aegean} directory with:

\begin{verbatim}
make config
\end{verbatim}

The compilation and download of the application is then best done within
the \code{patmos} directory with:

\begin{verbatim}
make APP=hello_puts comp download
\end{verbatim}

This application is the same single core \emph{Hello World} application that
we used in Section~\ref{sec:elf:files}. However, here we just compiled the
application and downloaded it via the serial port. We synthesized and configured
the FPGA from within the Aegean project for the multi-core version.

\todo{We shall have here three simple hello world applications: (1) just plain shared memory 4 cores saying hello - DONE -,
(2) a CMP program that uses shared memory, and (3) a simple NoC setup.}


%[2014-02-28 17:24:08 ] Stefan Hepp: #include <machine/patmos.h>
%[2014-02-28 17:24:22 ] Stefan Hepp: zu finden in patmos-newlib/newlib/libc/machine/patmos/machine/patmos.h

\section{The Xilinx ML605 Platform}

For the evaluation within the T-CREST project the Xilinx ML605 FPGA board was chosen as the `standard'
evaluation platform. The T-CREST platform contains, besides several Patmos' connected with the Argo NoC,
a memory tree, called BlueTree, from UoY and the time-predictable memory controller from TU/e. As the
building this platform needs some non-free tools and including closed source code, we provide prebuilt
configurations of the T-CREST platform as bit files available for download:

\begin{itemize}
\item A 4 core version: \url{http://patmos.compute.dtu.dk/t-crest-4core.bit}
\item A 16 core version: 
\end{itemize}

To configure the FPGA use the IMPACT software from Xilinx (command \code{impact}), which is part of the Xilinx ISE package
and needs no license (It is also available in a smaller Lab package). To compile an application and
download it to the ML605 follow the exact same steps as for the Altera CMP version, e.g., from
within the \code{patmos} directory:

\begin{verbatim}
make APP=hello_puts comp download
\end{verbatim}

\subsection{Getting the Xilinx Configuration Cable to Work}

Xilinx does not support Ubuntu (at least the last few versions) directly. The following description
is a summary of the help from Jamie.

Copy some Xilinx cable specific files to \code{/usr/share} with:

\begin{verbatim}
sudo cp /opt/Xilinx/14.7/ISE_DS/ISE/bin/lin/install_script/install_drivers/\
linux_drivers/pcusb/*.hex /usr/share
\end{verbatim}
 
Ensure that \code{fxload} is installed with:
\begin{verbatim} 
sudo apt-get install fxload
\end{verbatim}

Create \code{/etc/udev/rules.d/80-xusbdfw.rules} with following content:

\begin{tiny}
\begin{verbatim}
# version 0003
ATTR{idVendor}=="03fd", ATTR{idProduct}=="0008", MODE="666"
SUBSYSTEM=="usb", ACTION=="add", ATTR{idVendor}=="03fd", ATTR{idProduct}=="0007", RUN+="/sbin/fxload -v -t fx2 -I /usr/share/xusbdfwu.hex -D $tempnode"
SUBSYSTEM=="usb", ACTION=="add", ATTR{idVendor}=="03fd", ATTR{idProduct}=="0009", RUN+="/sbin/fxload -v -t fx2 -I /usr/share/xusb_xup.hex -D $tempnode"
SUBSYSTEM=="usb", ACTION=="add", ATTR{idVendor}=="03fd", ATTR{idProduct}=="000d", RUN+="/sbin/fxload -v -t fx2 -I /usr/share/xusb_emb.hex -D $tempnode"
SUBSYSTEM=="usb", ACTION=="add", ATTR{idVendor}=="03fd", ATTR{idProduct}=="000f", RUN+="/sbin/fxload -v -t fx2 -I /usr/share/xusb_xlp.hex -D $tempnode"
SUBSYSTEM=="usb", ACTION=="add", ATTR{idVendor}=="03fd", ATTR{idProduct}=="0013", RUN+="/sbin/fxload -v -t fx2 -I /usr/share/xusb_xp2.hex -D $tempnode"
SUBSYSTEM=="usb", ACTION=="add", ATTR{idVendor}=="03fd", ATTR{idProduct}=="0015", RUN+="/sbin/fxload -v -t fx2 -I /usr/share/xusb_xse.hex -D $tempnode"
\end{verbatim}
\end{tiny}

Restart the udev service with:

\begin{verbatim} 
sudo udevadm control --reload-rules
\end{verbatim}

Make sure that libusb is installed (e.g., in \code{/lib/i386-linux-gnu} on a 32-bit Ubuntu) and make a symbolic link with

\begin{verbatim} 
sudo ln -s libusb-1.0.so.0 libusb.so
\end{verbatim}

Best restart your machine and connect the USB cable again.

\paragraph{Using iMPACT}

Start impact from a terminal with 

\begin{verbatim} 
impact
\end{verbatim}

Impact pops up some dialog boxes:

Do you want iMPACT to automatically load the last saved project for you? -- answer with \emph{No}.

Do you want the system to automatically create and save a project file for you? -- answer \emph{Yes}.

Next window click Ok. iMPACT should detect the JTAG chain with two devices. Answer the
following dialog boxes wit \emph{No} and \emph{Cancel}.

Right-click on the xc6vlx240t device and select \emph{Assign New Configuration File} and select
the provided .bit file (e.g., \code{t-crest-4core.bit}). Answer the following question about attached
Flash PROMs with \emph{No}.

Right-click again on the FPGA symbol and select \emph{Program}. Select \emph{Ok} on the next
dialog box and the FPGA shall be configured.

Then compile and download an application as described above.

\paragraph{Installing the Xilinx Tools}

After extracting the tools with \code{tar} the install procedure is started within the
\code{Xilinx\_*} directory with:

\begin{verbatim}
sudo ./xsetup
\end{verbatim}

\paragraph{Starting Xilinx ISE}

In some setups it is needed to source a setup script, e.g.:

\begin{verbatim}
source /opt/Xilinx/14.7/ISE_DS/settings64.sh
\end{verbatim}

Then ISE can be started with \code{ise}.

\subsection{Updating the Patmos Cores with Aegean}

The correct Verilog file for the two version of Patmos (core 0 that downloads an application and the other cores)
is built with the \emph{Aegean} tool. The 4 cores version is built with:

\begin{verbatim}
make platform AEGEAN_PLATFORM=ml605_4core
\end{verbatim}

% make compile AEGEAN_PLATFORM=ml605_4core

A 16 core version is available as well. The generated Verilog files are the same,
but the schedule for the Argo NoC is different (which is copied to
\code{t-crest/patmos/c/nocinit.c}).

All generated file can be cleaned with \code{make cleanall}.

The configuration of T-CREST with Bluetree and the TU/e memory controller
is available via a .tgz file, exchanged via email to protect IP rights.
Therefore, they are not integrated in Aegean and some manual code copying is needed.
The \code{ml605.tgz} shall be extracted within the \code{t-crest} directory.
Copy the Patmos Verilog files (\code{ml605mPatmosCore.v} and \code{ml605mPatmosCore.v})
from the build directory (\code{t-crest/aegean/build/ml605\_4core}) into \code{t-crest/ml605}.

\section{Testing}

Patmos base functionality can be tested by comparing the execution of the simulator with
the execution of the emulator. \todo{Write more on how it works. Somewhere we should also
talk about the two different ways to build Patmos: within the patmos repro and with build.sh
where the emulator gets installed.}
Within the \code{patmos} folder execute:

\begin{verbatim}
make test
\end{verbatim}

More testing can be performed with the programs included in the benchmark repository.
This repository is not included in the default checkout and build. Therefore, within the
folder \code{t-crest} execute

\begin{verbatim}
misc/build.sh patmos
misc/build.sh -t bench
\end{verbatim}

to checkout the benchmarks, compile them, and execute them. Building Patmos via the build script
also ensures that the correct emulator is used. Be aware that this is
a very lengthy task; it takes on a MacBook Pro more than 3 hours.

\section{Worst-Case Execution Time Analysis}

The aiT WCET analysis tool supports Patmos as target. The benchmark collection
of T-CREST (in folder \code{bench}) includes targets for WCET analysis.

When the aiT version for Patmos (\code{a3patmos}) is in the path, the build of
the benchmarks includes WCET analysis tasks, where appropriate.

In \code{bench/build/Malardaln/src} start the tests including Platin WCET analysis with \code{ctest}.


\section{ModelSim License}
In the case that you have a DTU Compute login you can access the license servers from outside the DTU network by setting up an SSH tunnel.
An example of how such a tunnel can be set up follows, you need to insert you own username.

\begin{verbatim}
ssh -L 1717:angel2:1717 -L 1718:angel2:1718 ${USERNAME}@sshlogin.compute.dtu.dk
\end{verbatim}
%% $

When the SSH tunnel is setup the LM\_LICENSE\_FILE needs to be set to:
\begin{verbatim}
LM_LICENSE_FILE=1717@localhost
\end{verbatim}

This way of setting up an SSH tunnel might also work for other institutions.

\paragraph{License settings for ModelSim and Xilinx}

\begin{verbatim}
export LM_LICENSE_FILE=1717@angel1:1717@angel2:1717@angel3
export XILINXD_LICENSE_FILE="2100@eda1.imm.dtu.dk"
\end{verbatim}





\chapter{Tools}

Along with Patmos come several tools; this chapter describes these
tools and how to use them.

\section{Simulation, Emulation, and Execution}

\subsection{pasim}

The Patmos simulator \texttt{pasim} provides a high-level simulation
of Patmos. It is useful for quick evaluations of different hardware
configurations and for debugging applications. As it can provide
detailed reports about the application behavior, it is particularly
useful during the initial phases of application development.

\paragraph{Usage} The general usage of \texttt{pasim} is \texttt{pasim
  <file>}, where \texttt{<file>} may be a plain binary or an ELF
file. Tables~\ref{tab:pasimopts_gen}, \ref{tab:pasimopts_mem},
\ref{tab:pasimopts_cache}, and~\ref{tab:pasimopts_sim} show the
various options of the simulator. For memory/cache sizes the following
units are allowed: \texttt{k}, \texttt{m}, \texttt{g}, or \texttt{kb},
\texttt{mb}, \texttt{gb}.

\begin{table}[b!]
  \centering
  \caption{General options for \texttt{pasim}}
  \label{tab:pasimopts_gen}
  \begin{tabular}{>{\ttfamily}l<{}p{.6\textwidth}}
    \toprule
    \multicolumn{1}{l}{Option} & Description \\
    \midrule
    -h [ ---help ]       & produce help message \\
    -c [ ---maxc ] arg   & stop simulation after the given number of cycles (default: infinity) \\
    -b [ ---binary ] arg & binary or elf-executable file (stdin: \texttt{-}) \\
    ---debug [=arg]      & enable step-by-step debug tracing after cycle, default: 0 \\
    ---debug-fmt arg     & format of the debug trace (\texttt{short}, \texttt{trace}, \texttt{instr}, \texttt{blocks}, \texttt{calls}, \texttt{calls-indent}, \texttt{default}, \texttt{long}, \texttt{all}) \\
    ---debug-file arg    & output debug trace in file (stdout: \texttt{-}, default: stderr) \\
    ---debug-intrs       & print out all status changes of the exception unit. \\
    ---debug-nopc        & do not print PC and cycles counter in debug output \\
    -o [ ---stats-out ] arg & write statistics to a file (stdout: \texttt{-}, default: stderr) \\
    ---print-stats arg   & print statistics for a given function only. \\
    ---flush-caches arg  & flush all caches when reaching the given address (can be a symbol name). \\
    -V [ ---full ]       & full statistics output \\
    -v [ ---verbose ]    & enable short statistics output \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}
  \centering
  \caption{Memory Options for \texttt{pasim}}
  \label{tab:pasimopts_mem}
  \begin{tabular}{>{\ttfamily}l<{}>{\ttfamily}r<{}p{.6\textwidth}}
    \toprule
    \multicolumn{1}{l}{Option} & \multicolumn{1}{l}{Default} & Description \\
    \midrule
    -g [ ---gsize ] arg  & 64m  & global memory size in bytes \\
    -G [ ---gtime ] arg  & 7    & global memory transfer time per burst in cycles \\
    -t [ ---tdelay ] arg & 0    & read delay to global memory per request in cycles \\
    ---trefresh arg      & 0    & refresh cycles per TDM round \\
    ---bsize arg         & 16   & burst size (and alignment) of the memory system. \\
    ---psize arg         & 0    & Memory page size. Enables variable burst lengths for single-core. \\
    -p [ ---posted ] arg & 0    & Enable posted writes (sets max queue size) \\
    -l [ ---lsize ] arg  & 2k   & local memory size in bytes \\
    ---mem-rand arg      & 0    & Initialize memories with random data \\
    ---chkreads arg      & none & Check for reads of uninitialized data, either per byte (\texttt{warn}, \texttt{err}) or per access (\texttt{warn-addr}, \texttt{err-addr}). Disables the data cache. \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}
  \centering
  \caption{Cache options for \texttt{pasim}}
  \label{tab:pasimopts_cache}
  \begin{tabular}{>{\ttfamily}l<{}>{\ttfamily}r<{}p{.6\textwidth}}
    \toprule
    \multicolumn{1}{l}{Option} & \multicolumn{1}{l}{Default} & Description \\
    \midrule
    -d [ ---dcsize ] arg & 2k     & data cache size in bytes \\
    -D [ ---dckind ] arg & lru2   & kind of direct mapped/fully-/set-associative data cache (\texttt{ideal}, \texttt{no}, \texttt{dm}, \texttt{lru[N]}, \texttt{fifo[N]}) \\
    ---dlsize arg        & 0      & size of a data cache line in bytes, defaults to burst size if set to 0 \\
    -s [ ---scsize ] arg & 2k     & stack cache size in bytes \\
    -S [ ---sckind ] arg & block  & kind of stack cache (\texttt{ideal}, \texttt{block}, \texttt{lblock}, \texttt{dcache}) \\
    -C [ ---icache ] arg & mcache & kind of instruction cache (\texttt{mcache}, \texttt{icache}) \\
    -K [ ---ickind ] arg & lru2   & kind of direct mapped/fully-/set-associative I-cache (\texttt{ideal}, \texttt{no}, \texttt{dm}, \texttt{lru[N]}, \texttt{fifo[N]} \\
    ---ilsize arg        & 0      & size of an I-cache line in bytes, defaults to burst size if set to 0 \\
    -m [ ---mcsize ] arg & 2k     & method cache / instruction cache size in bytes \\
    -M [ ---mckind ] arg & fifo   & kind of method cache (\texttt{ideal}, \texttt{lru}, \texttt{fifo}) \\
    ---mcmethods arg     & 16     & Maximum number of methods in the method cache, defaults to number of blocks if zero \\
    ---mbsize arg        & 8      & method cache block size in bytes, defaults to burst size if zero \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}
  \centering
  \caption{Simulator options for \texttt{pasim}}
  \label{tab:pasimopts_sim}
  \begin{tabular}{>{\ttfamily}l<{}>{\ttfamily}r<{}p{.54\textwidth}}
    \toprule
    \multicolumn{1}{l}{Option} & \multicolumn{1}{l}{Default} & Description \\
    \midrule
   ---cpuid arg           & 0          & Set CPU ID in the simulator \\
   -N [ ---cores ] arg    & 1          & Set number of CPUs (enables memory TDM) \\
   ---freq arg            & 80         & Set CPU Frequency in Mhz \\
   ---interrupt arg       & 1          & enable or disable interrupts \\
   ---mmbase arg          & 0xf0000000 & base address of the IO device map address range \\
   ---mmhigh arg          & 0xffffffff & highest address of the IO device map address range \\
   ---cpuinfo\_offset arg & 0x000      & offset where the cpuinfo device is mapped \\
   ---excunit\_offset arg & 0x100      & offset where the exception unit is mapped \\
   ---timer\_offset arg   & 0x200      & offset where the timer device is mapped \\
   ---uart\_offset arg    & 0x800      & offset where the UART device is mapped \\
   ---led\_offset arg     & 0x900      & offset where the LED device is mapped \\
   -I [ ---in ] arg       & -          & input file for UART simulation (stdin: \texttt{-}) \\
   -O [ ---out ] arg      & -          & output file for UART simulation (stdout: \texttt{-}) \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{patmos-emulator}

The tool \texttt{patmos-emulator} provides a C++-based simulator that
is derived from the actual hardware description. While it is slower
and less flexible than \texttt{pasim}, its behavior is identical to
the behavior of actual hardware. It is therefore useful for
investigating cases where the behavior of the simulator diverges from
the behavior in the FPGA. The emulator can also generate wave form
traces, which allow the investigation on a level similar to
Verilog/VHDL-based simulations.

\paragraph{Usage} 

The general usage is \texttt{patmos-emulator [<file>]}. When invoked
without argument, \texttt{patmos-emulator} executes the code in the
boot ROM of the processor. When given an ELF file as argument, the
emulator loads the file and executes it
directly. Table~\ref{tab:emulopts} shows the command-line options for
the emulator.

\begin{table}
  \centering
  \caption{Options for \texttt{patmos-emulator}}
  \label{tab:emulopts}
  \begin{tabular}{>{\ttfamily}l<{}p{.66\textwidth}}
    \toprule
    \multicolumn{1}{l}{Option} & Description \\
    \midrule
    -h            & Print help \\
    -i            & Initialize memory with random values \\
    -k            & Simulate random input from keys \\
    -l <N>        & Stop after \texttt{<N>} cycles \\
    -p            & Print method cache statistics \\
    -r            & Print register values in each cycle \\
    -v            & Dump wave forms file \texttt{Patmos.vcd} \\
    -I <file>     & Read input for UART from file \texttt{<file>} (stdin: \texttt{-}, default: stdin) \\
    -O <file>     & Write output from UART to file \texttt{<file>} (stdout: \texttt{-}, default: stdout) \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{config\_altera}

The script \texttt{config\_altera} configures an Altera FPGA using the
tool \texttt{quartus\_pgm} provided by Altera.

\paragraph{Usage}

The usage of the script is \texttt{config\_altera [-b <blaster>] [-h]
  <file>}. The option \texttt{-h} prints a basic help. The option
\texttt{-b} specifies the blaster type for FPGA configuration; by
default, the blaster type is \texttt{USB-Blaster}. The argument
\texttt{<file>} specifies a \texttt{.sof} file with the bit stream for
FPGA configuration.

\subsection{config\_xilinx}

The script \texttt{config\_xilinx} configures a Xilinx FPGA using the
tool \texttt{impact} provided by Xilinx.

\paragraph{Usage}

The usage of the script is \texttt{config\_xilinx [-h] <file>}. The
option \texttt{-h} prints a basic help. The argument \texttt{<file>}
specifies a \texttt{.bit} file with the bit stream for FPGA
configuration.

\subsection{patserdow}

The tool \texttt{patserdow} downloads an ELF file via a serial line to
the FPGA and forwards output to and from the downloaded
application. The download protocol uses CRC checksums to verify the
integrity of the downloaded data. The \texttt{patserdow} tool
terminates when the application on the FPGA terminates, with the same
exit code as the application.

\paragraph{Usage}

The general usage is \texttt{patserdow [-v] [-t <time>] [-h] <port> <file>}. The
option \texttt{-h} prints a basic help. The option \texttt{-v} turns
on a verbose mode, where information about the file to be downloaded
and the progress of the downloading process is printed to
stderr. The option \texttt{-t} specifies a time out after which execution is terminated.
Output from the application is written to stdout; input to the
application is read from stdin. The argument \texttt{<port>} specifies
the serial port to be used for downloading. The argument
\texttt{<file>} specifies the ELF file to be downloaded.

\subsection{patex}

The tool \texttt{patex} combines FPGA configuration and application
download such that ELF files can be executed on the FPGA without
manual intervention. It can therefore act as a drop-in replacement for
\texttt{pasim} and \texttt{patmos-emulator}. As \texttt{patex}
executes the application on actual hardware, it is particularly useful
for applications where simulation or emulation would be prohibitively
slow.

\paragraph{Usage}

The general usage is \texttt{patex [-I <file>] [-O <file] <file>}. The
argument for the option \texttt{-I} specifies where input to the UART
should be read from. The argument for the option \texttt{-O} specifies
where UART ouput should be written to.

The environment variable \texttt{PATEX\_CONFIG} determines how the
FPGA is configured. Permissible values are: \texttt{Make} (the default
value), \texttt{Altera}, or \texttt{Xilinx}.
\begin{itemize}
\item \texttt{Make} means that the FPGA is configured by calling
  \texttt{make config} in the directory specified in environment
  variable \texttt{PATMOS\_HOME}. When this variable is unset,
  \texttt{patex} uses the directory where it was installed from.
\item \texttt{Altera} means that the FPGA is configured by calling
  \texttt{config\_altera} with the file specified in environment
  variable \texttt{PATEX\_CONFIGFILE}. If the environment variable
  \texttt{BLASTER\_TYPE} is set, it is used as the blaster type.
\item \texttt{Xilinx} means that the FPGA is configured by calling
  \texttt{config\_xilinx} with the file specified in environment
  variable \texttt{PATEX\_CONFIGFILE}.
\end{itemize}

\texttt{patex} recognizes URLs for \texttt{PATEX\_CONFIGFILE} and
downloads the file using \texttt{wget} if necessary. The protocols
\texttt{http}, \texttt{https}, and \texttt{ftp} are supported.

The environment variable \texttt{COM\_PORT} sets the serial port for
downloading. When this variable is unset, \texttt{patex} uses the
\texttt{COM\_PORT} variable from the Makefile at the time of
installation. The environment variable \texttt{TIMEOUT} sets a timeout
in seconds. By default, \texttt{patex} terminates download and
execution after 300 seconds. Setting the environment variable
\texttt{VERBOSE} to \texttt{true} turns on verbose output.

\section{Patmos Developer Tools}

This section describes tools that are useful when working on Patmos
itself, but are of little interest when developing applications.

\subsection{elf2bin}

The \texttt{elf2bin} tool converts ELF files to binary files.

\paragraph{Usage}

The \texttt{elf2bin} tool has two modes. In default mode, its usage is
\texttt{elf2bin <infile> <outfile1> <outfile2>} and it dumps
executable segments to file \texttt{<outfile1>} and other segments to
\texttt{<outfile2>}. For the non-executable segments, it uses a
displacement of \texttt{0x80000000}, such that data that is mapped to
address \texttt{<N>} is dumped to position \texttt{<N>-0x80000000} in
the output file.

The second mode of \texttt{elf2bin} is a ``flat'' mode, with the usage
\texttt{elf2bin -f <infile> <outfile>}. In that mode, \texttt{elf2bin}
generates a flat output file, without any displacement. This file can
be post-processed (e.g., with \texttt{hexdump -v -e '"\%d,"' -e '" // \%08x\textbackslash n"'})
to generate a representation of the data for Verilog/VHDL-based
simulations of external memory.

\subsection{pacheck}

The tool \texttt{pacheck} performs a ``sanity'' check of binaries and
ELF files. While not being complete, it detects common errors such as
control-flow instruction inside branch delay slots.

\paragraph{Usage}

The usage of \texttt{pacheck} is \texttt{pacheck [-h|---help]
  [-v|---verbose] [[-b|---binary] <input>]}. The option \texttt{-h}
prints a help message. The option \texttt{-v} makes \texttt{pacheck}
verbose. By default, \texttt{pacheck} reads from stdin; a file for
checking can be given either as command-line argument or as argument
to the option \texttt{-}.

\subsection{paasm}

The Patmos assembler \texttt{paasm} provides a basic assembler. It
generates binary files and should be used only for writing very basic
tests of Patmos. For developing applications in assembly, please use
the assembler provided by the compiler, which is more complete and in
particular supports the generation of ELF files.

\paragraph{Usage}

The usage of \texttt{paasm} is \texttt{paasm <input> <output>}.

\subsection{padasm}

The Patmos disassembler \texttt{padasm} is the counterpart of
\texttt{paasm}, and similar restrictions apply. For general
development, please use the \texttt{patmos-llvm-objdump} tool provided
by the compiler.

\paragraph{Usage}

The usage of \texttt{padasm} is \texttt{padasm <input> <output>}.





% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\chapter{The Patmos Compiler}
\label{sec:compiler}

\input{compiler}


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\chapter{Potential Extensions}

\section{Multiply / Wait / Move from Special}

\begin{itemize}
  \item Attaching a ready flag with all special registers.
  \item Specify destination special register with all decoupled operations; the
        operation sets/resets the ready flag accordingly.
  \item Wait operates on ready flags of special registers.
  \item Merged variant of Wait + Move from Special
  \item Wait with 16-bit mask to wait for multiple outstanding results.
\end{itemize}

This would be nice since it would allow to reload all special registers from
memory without going through the general purpose registers. It would be a
unified interface for decoupled operations and give more freedom to handle
parallel decoupled operations (pipelined multiplies, loads). We could apply this
also to the general purpose registers instead of the special registers.

\stefan{I think it makes more sense to use the ready flags with the general purpose registers. Then we can simply replace
all blocking and decoupled loads with special move by one unified load to a general purpose register. This however means
that all operations can potentially stall.}

\stefan{Regarding having additional write ports for the register file: We could still disallow multiple parallel loads by stalling a load
instruction until the last memory op is completed (else we would also need to take some special care of stores if loads and stores can be in progress at the same
time), this would not be any worse than the current ISA (currently we cannot have multiple loads to main memory in parallel). If a load is
ready, I guess we could just stall the pipeline for one cycle to write to the register. Again, this may still be better than the
current ISA, since we do not need the code space for the additional move from special instruction, but it may cost one stall whereas the
move-from-special could be scheduled in the second slot parallel to some other operation (ok, but then its not so RISC anymore..).}

\section{Bypass load checks data cache}

Let the bypass load use the data cache if the data is cached. If the data is not in the cache, load it from main memory, but do not update
the data cache (in contrast to the normal load). Therefore the compiler could use bypass to load data that will not be used a second time or
that might have a negative impact on the cache analysis, but we still take advantage of the cache if the data is already in the cache.

\stefan{For now the bypass is defined as load always from memory, even if it is in the cache, but there is no real disadvantage to checking the
cache first (except that bypass cannot be used to achieve a perfectly stable timing). But should a bypass update the LRU if it is a cache
hit? (probably not, it should not modify the cache state).

On the other hand, for synchronization we need a bypass that \emph{always} checks main memory. For consistency reasons, we may want to
update the data cache if it contains the accessed address.}

\section{Merged Stack Cache Operations and Function Return}

This might require an additional special-purpose register(?) to track the size
of the last reserve instruction (this register might also be set explicitly).
However, it would might reduce the number of ensure instructions needed.

Another option would be to merge the return and stack free operations. Both
instructions belong to the same function and, due to the simpler semantics of
the free, the combination would be easier to implement.

\stefan{I doubt that merging those functions would actually gain something. It reduces the flexibility for the compiler to perform ensure
only where needed, may limit the possibilities for passing data over the stack cache, and requires additional
code to restore the special registers that are required to track the size of the stack. Only gain I see is when the word in front of the
method code that stores the size of the method is used to store the stack size as 16bit value, and limit the size of the method to a 16bit
value. Then no additional data needs to be transferred. The stack control instructions would still be required to allow the compiler to
allocate stack e.g. only in certain contexts.}

\martin{If stack operations only happens at function call
and return this merge would make sense. It makes also
very clear that M$ memory access and S$ memory access are coordinated.}

\section{Non-Blocking Stack Control Instructions}

Currently, all stack control operations, except \texttt{sfree}, are blocking. It
might be useful to define non-blocking variants or define them to be
non-blocking in all cases.

It is questionable whether this would actually buy us anything. Most
\texttt{sres} instructions will be followed by a store to the stack cache
(spill of saved registers). It might be more profitable for \texttt{sens}
instructions.

\section{Freeze Cache Content}

\begin{itemize}
  \item Bypass load can be used to avoid cache updates, but not on per-context basis (we cannot lock the cache and then call any function
  and assume the function does not update the cache. Instead we would need to generate function variants that only use bypass loads).
  \item Method cache freeze? Or should we just use a I-SPM for this if we want instruction cache locking?
\end{itemize}

\section{Unified Memory Access}

\stefan{All our memories (except the stack cache) use a unified address space, but due to the typed loads, references must include both address and
type of the cache. Since the type is encoded in the code, any generated code can only use one type of cache or SPM.
If we have a function with $m$ arguments and $n$ different caches or ways of accessing
memory, in the worst case we would need $m^n$ copies of that function to handle all cases (increases instruction cache costs!). We also need to expose this to the programmer,
either through having different names for the functions (very ugly and annoying to use, remember that this is transitive, you need to copy
your whole libraries!), or by having a type system on top of the C types, which means implementing some sort of overloading in C and
auto-generating variants of functions.

Note: we need typed loads to tell the processor which cache (not) to use. We also need a shadow stack not only due to typed loads,
but also due to the write-back policy of the stack cache (would make consistency a night-mare if we would allow to access stack-cache
allocated data over the data cache!).
}
\martin{we discussed that issue in The Vienna mini workshop and should continue to discuss it.}

Instead of having typed loads per cache or SPM, maybe have types per ``use-case scenario'', use local memory based on address
\begin{itemize}
\item Type for stack access (guaranteed hit, can be used in both slots)
\item Type for guaranteed hit (any local SPM access, access to data cache must be always hit, else undefined result)
\item Type for unknown data access (access SPM or data cache, or main memory and update data-cache)
\item Type for bypass (access SPM or main memory, do not allocate in data cache)
\item Maybe a type for no-allocate (access SPM, data cache or main memory, but do not allocate data in cache; could be useful to prevent
single loads from thrashing the cache), or use some sort of cache-lock instruction instead (could be useful to prevent a code sequence or function call from
thrashing the cache)
\end{itemize}

\stefan{
The idea behind the typed load is 1.~it makes analysis simpler by having guaranteed hit instructions, 2.~it makes the hardware
simpler and faster (I assume), no need to read the address to determine the local memory to use.
However, typed loads shift the analysis effort to the compiler, but while the analysis may make over-approximations about the accessed
memory, the compiler must always know the correct memory type, which requires either a precise analysis or help from the programmer by
additional annotations. An analysis can also be context-sensitive, but it is not possible for the compiler to generate ``context-sensitive
typed loads''. A better way for 1.~could be to generate annotations for memory accesses by the compiler instead of putting the
information into the code, which then can be context-sensitive and imprecise and allows for better code reuse, although this (mostly) eliminates the advantages of 2.
Might be interesting to compare those two approaches.
}

\stefan{Note: if we use a DMA controller, we do not need separate memcpy functions depending on the source and destination memory, since the
DMA controller can determine source and target based on the addresses (hopefully).
}

\section{Memory Management Unit}
\begin{itemize}
  \item Simple software managed TLB.
  \item Main idea is to provide protection and separation.
  \item Could be used for memory testing.
  \item No traps. Instead, reset or kill thread?
\end{itemize}

\section{Supervisor Mode}
\label{sec:supervisor}
\begin{itemize}
  \item To restrict reconfiguration of critical components (e.g., TLB, Interrupt
        Tables).
  \item Transfer to supervisor mode, e.g., via \texttt{syscall}.
  \item Might be handy when running multiple threads or an OS.
\end{itemize}

\section{DMA Interface}
\begin{itemize}
  \item Transfers between local and global memory
  \item Through special registers
  \item Alternatively, dedicated instructions \texttt{dmastart} and \texttt{dmalen}
\end{itemize}

\begin{bytefield}{32}
\bitheader{0-31}\\
\bitbox{1}{x} & \bitbox{5}{01010} &
\bitbox{4}{Pred} & \bitbox{5}{Type} & \bitbox{5}{Ra} & \bitbox{5}{Rs} &
\bitbox{7}{} \\
\end{bytefield}

\begin{tabular}{lll}
Type  & Mnemonic & Operation \\ \hline
00001 & dma.sp   & Start memory copy \\
      &          & which contain the word \\
xx001 & st.sc    & Stack cache, no write through to \\
      &          & main memory, never wait \\
xx010 & st.sp    & Scratchpad, no write through to \\
\end{tabular}

\stefan{If the I-SPM and D-SPM has a separate connection to the NoC, we may
also want a separate wait that stalls until the transfer is complete, independent of other memory transfers (load and stores using the data cache).}

\jack{Very useful to have both a blocking and a non-blocking
version of this instruction. The blocking version is probably
more important, though, so if it has to be one or the other,
then blocking should be it.

I-SPM should not really be a concern right now. I'd see this as
a store for permanently-resident code, therefore not requiring DMA.

What does worry me here is the number of DMA routes that might be
possible. I think we need to carefully consider what DMA operations
are really needed. There are three sources/destinations of interest:
stack cache (sc), local memory (lm) and global shared memory (gm),
and they're all effectively in different memory spaces.

I think we want to be able to transfer data from either
lm or sc, to gm. And vice-versa. This gives four DMA routes:
gm~$\rightarrow~$lm, gm~$\rightarrow~$sc, lm~$\rightarrow~$gm,
sc~$\rightarrow~$gm.

I would suggest that there should be a 2-bit field to say which DMA route
should be used and a 1-bit field to say if the operation should block
or not.}

\stefan{The stack cache spill and fill ops are performed by dedicated instructions, so we do not need to support this in the ISA (but it
will probably be handled by the DMA in the background). Do we also handle method cache fill by the DMA (probably yes)? Prefetching into the data cache
(probably not)?

Accessing main memory over the data cache or with bypass will basically access words in more or less random locations. Stack cache fill and
spill, method cache fill, and DMA transfers from main memory to scratchpad and back perform burst writes. Communication between scratchpads
may be somewhere in between? Maybe we could have two connections to the NoC, or two NoCs, with different package sizes,.. to support the
different transfer scenarios more efficiently. However, the bottleneck will
then be the SDRAM controller.}

\martin{I see also (at least ;-) two NoCs: one for main memory related transfers and one for
message passing communication between SPMs. And those have kind of different DMAs.
The SPM message passing has a real DMA -- I mean one that is programmed by the
CPU like: start from this address and load so many words. The other (caches) memory
transfer is also done by a small state machine - be it cache line fill, method cache several
block fill, or stack cache range fill. However, this bursty transfer is more implicit and
I would not call it DMA.

However, this might just be a naming convention issue. Maybe we are playing
with architectures and naming conventions in a spectrum. E.g. instruction
memory: plain I\$ -- I\$ with prefetch instructions -- method cache -- SPM with
pointer redirect (address translation) -- plain SPM in its own address space.}

\section{Data scratchpad}

\begin{itemize}
  \item Every core has its D-SPM with its own address range (all in the same address space), a core can write to the D-SPM of another core
  by writing to an address of the SPM of that core.
  \item Maybe have some sort of protection mechanism, to prevent cores from writing to any address in any remote SPM
  \item How do we handle writes to the same address by (remote) dma transfers and local writes (this might prevent local load and stores to
  the SPM from completing in a single cycle)?  \jack{This sounds
    like undefined behavior. The program should avoid doing this.
    But local loads/stores must take priority over remote loads/stores
    to SPM (including locally-initiated DMA transfers) because otherwise
    we will not have single-cycle access to SPM. There must be fixed-priority
    arbitration giving the CPU top priority.}
\end{itemize}

\stefan{The compiler needs to generate typed loads for SPM access. How do we tell the compiler when to use SPM access, without causing too
much pain to the programmer (we would need to annotate all variables, including function arguments and pointers to SPM allocated data).
Same problem here as with stack cache and second data cache due to typed access: Passing data to a function requires the function to know in which memory the
data is stored. We need specialized functions for
memory types of parameters, in all occurring combinations, this increases code size and method cache misses.}

\martin{I see the D-SPM mainly as buffer for core-to-core message passing.
DMAs transfer data between the NoC and the D-SPM on one memory port
and the CPU accesses it on the other (we are assuming two ports that can
change the direction, which was (is?) not available on all FPGA families).

Part of this D-SPM can also be used just to hold core local data. We don't
need to have an extra one.

Write access to the same address from two sides is simply undefined.
Why shall we provide HW for that? It is a programming error anyway.}

\section{Halt}
\fb{Might not be needed for now. In the simulator we could simply jump to a
label \texttt{exit} or \texttt{halt} or do an explicit syscall to quit the
simulation.}

\section{Floating-Point Instructions}

\section{Prefetching}

\begin{itemize}
  \item For method cache
  \item For local memory
\end{itemize}

\stefan{Prefetching with Method cache with FIFO is tricky, maybe we can use an I-SPM to store code that is executed while we prefetch the
method cache.}

\section{Data Caches}

\begin{itemize}
  \item Add a second (possibly larger), simple (direct mapped,..) data cache, to be used when the pointer address is known at compile time
    (i.e., a load does not destroy the whole cache state in the analysis), for array operations, ..
  \item We would need additional types in the load operation for that cache, but there are only two unused types left. Either use only
    blocking (?) loads and only word and byte (?) access, or replace some lesser used types, or even introduce a new opcode somehow..
\end{itemize}

\stefan{There were some plans about introducing two separate data caches, one direct mapped and a small fully associative (B1.1.6
in the final DoW), with the intention to avoid having loads from unknown addresses destroy the direct mapped cache state in the analysis.
Therefore we might want to reserve some types for loads that use a second data cache (if we do not use write-allocation for store, we do not need to make
this distinction for the store operation).}

\stefan{We also need to define how the store operation performs the data cache updates. I would suggest/prefer to merge the \texttt{gm} and
\texttt{dc} store types, use write-through (to avoid hard-to-analyze write-back costs at some random loads) without write-allocation (to
avoid problems with byte and half-word stores and unnecessary cache conflicts). A store should update all data caches that contain the data.
Then a load immediately after a store to the same address does not need to wait for the store write-through to complete if the load is a cache hit.}

\stefan{Actually, a second data cache with typed loads would be tricky for the compiler. We cannot simply pass a pointer to a constant to a
function that takes any kind of data. if the constant is in a different cache the function does not know this and loads the data also into
the first cache, making the second cache very inefficient.}

\martin{We can overdue it by adding some more data caches: one for
static data (as mentioned before where addresses are known) and one
for constants. The difference is cache coherency, which is not needed
for constants. But are we considering cache coherence?}

\section{Instruction scratchpad}

\begin{itemize}
\item For instruction handlers or other code that should not destroy the method cache
\item Could be used to store code that is executed at a call site (even if the method cache entry of the caller gets replaced)
\item Replacement of code at runtime, statically scheduled or with some sort of software-controlled replacement strategy (maybe this could
be used to prevent threads from destroying the I-cache of real-time tasks)
\item Keep frequently used code on the I-SPM, can be used to do some sort of cache locking (instead of somehow locking the method cache).
\end{itemize}

\jack{I suggest that an I-SPM should be used only to store
permanently resident code. Interrupt handlers, scheduler,
that sort of thing.  Otherwise we need a more complex DMA
controller (more ports) and we need to explain why the I-SPM is
sometimes better than using the method cache. This is a bit tricky
because while dynamic (run-time replacement) I-SPM allocation strategies
do have the advantage of being able to load parts of methods, or pack
multiple methods into a single load, and thus get better performance
in some cases, you can get the same behavior by manipulating the
control flow graph (inlining/exlining/combining methods) and using
a method cache. So it is hard to make that argument in a report.}


\section{Wired-AND/OR for predicates}

Let \texttt{cmp} be some operation that sets a predicate \texttt{Pd} and is predicated by \texttt{Pred}.
Then we could define the following variants:
\begin{verbatim}
cond:   if (Pred)           Pd = <cmp>
and:    if (Pred && !<cmp>) Pd = False
or:     if (Pred &&  <cmp>) Pd = True
uncond: Pd = Pred && <cmp>
\end{verbatim}
Note that we do not need to read \texttt{Pd}, but the last variant uses \texttt{Pred} as input, not as write-enable signal. First variant is
the normal (conditional) execution. The last variant forces \texttt{Pd} to \texttt{false} if \texttt{Pred} is false, thus saving the
initialization of \texttt{Pd} or explicit \texttt{and} with \texttt{Pred} for code like
\begin{verbatim}
if (p1)  p2 = R1 < R2
if (p2)  ...
\end{verbatim}
The other variants can be used to implement stuff like
\begin{verbatim}
if (a != 0 && b < 5) { .. }

p1  = cmpnez r1,    addi r3 = r0 + 5;
p1 &= cmplt r2, r3
\end{verbatim}
To implement \texttt{a != 0 \&\& b > 1} we would need an additional bit that negates either the result of \texttt{<cmp>} or the value that is
assigned to \texttt{Pd} (including the \texttt{true} and \texttt{false} assignments).

Note that if we do not need \texttt{Pred}, we can do \texttt{and} and \texttt{or} simply as
\begin{verbatim}
Pd &= <cmp>  ... if ( Pd)  Pd = <cmp>
Pd |= <cmp>  ... if (!Pd)  Pd = <cmp>
\end{verbatim}
i.e., we use \texttt{Pd} as \texttt{Pred}.


\section{Deadline instruction}

\begin{bytefield}{32}
\bitheader{0-31}\\
\bitbox{1}{x} & \bitbox{5}{01011} &
\bitbox{4}{Pred} &
\bitbox{22}{Counter} \\
\end{bytefield}

Wait until the deadline counter reaches zero, then restart the counter with the given initial value.

\stefan{Do we want this? This is similar to the PRET deadline instruction. We could use this to fix the execution time
of some CFG region, e.g., if we know that in a sequence of load instructions at most one load will be a cache miss, but we do
not know which one, then we can set a deadline to that sequence that allows for one cache miss, and get stable timings for the
program without forcing every memory access that we cannot guarantee to be always-hit to be a cache-miss. We could also use
that instruction to verify the WCET results, by raising an exception if the counter already reached zero when the deadline instruction
is issued. However, we have no exception-handling in our ISA so far..}

\cullmann{For timing analysis, I see no benefit in having the deadline instruction.
Our aiT tool-chain copes well with block with variable durations and can use that to get actually a better WCET bound. (e.g. if for some calling contexts a block is fast, this will be exploited in the analysis)
On the other side, if a deadline instruction is around, we would need to keep track of the current active deadline counter which will increase the complexity of the analysis.
(if I understand it right, that you can at one time start such a deadline and later at an other point wait for it)
}
\stefan{The deadline instruction is basically a tool to make the \emph{measured} execution time more stable. The idea here is to set the
deadline counter based on the WCET analysis, not the other way round (we can set the counter to zero for analysis, so no deadline
instruction will ever wait and the analysis can ignore the instructions, and then use the analysis results to set the counters in the final
code).}
\stefan{Actually, there are only two real use-cases for a deadline instruction: test WCET analysis results (by throwing an exception if
deadline already expired when the instruction is executed, but this requires exception handling in our ISA first!), and making the timing of
\emph{output} produced by the program stable (by waiting on the deadline directly before producing some output; This allows to generate some
periodic signals without having some timer hardware or timer interrupts, i.e., without interrupting the control-flow, thus really bringing
the notion of time into the ISA!).

There is a third use-case: we can fix the execution time of basic-blocks or some code regions. This could be used to make the WCET
of the program more composable by reducing problems with timing anomalies, and to avoid cases where the processor state depends on
the timing of some previous instructions. However, I \emph{strongly} suggest to formally check our ISA and our code generator to be
free of timing anomalies,.., so that we avoid this use-case by design. We want to be able to calculate the WCET for some sub-CFG from the
WCET of the basic-blocks as easily as possible, so that we can keep track of the WCET/WCEP in the compiler when doing code
transformations.}

\chapter{Conclusion}
\label{sec:conclusion}

Patmos is the next cool thing in the dry world of real-time systems.

\bibliographystyle{abbrv}
\bibliography{patbib.bib}

\end{document}
